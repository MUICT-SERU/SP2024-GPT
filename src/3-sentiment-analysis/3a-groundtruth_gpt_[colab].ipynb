{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis using OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setup paths and common variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import csv\n",
    "import pandas as pd\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check whether API key exists (should be in your environment variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# Initialize the OpenAI client with your API key\n",
    "import os\n",
    "api_key = os.getenv('OPENAI_API_KEY')  # Replace with your actual OpenAI API key\n",
    "openai.api_key = api_key\n",
    "\n",
    "# %% [markdown]\n",
    "# Define the sentiment analysis prompt template\n",
    "\n",
    "# %%\n",
    "prompt_template = '''\n",
    "Analyze the sentiment of the Hacker News comment with the context of the AI-related story title found below under \"Input text:\" whether the comment is negative (-1), neutral (0), or positive (1) towards AI. First understand the meaning of the story title, then understand the meaning of the comment in the context of the story title, then analyze the sentiment of the comments in the context of the story title whether the comment is negative (-1), neutral (0), or positive (1) towards AI, and conclude the sentiment of the comment to only one best sentiment type.\n",
    "\n",
    "Sentiment can contain only a single number either:\n",
    "  -1 (for negative towards AI)\n",
    "  0 (for neutral towards AI)\n",
    "  1 (for positive towards AI)\n",
    "\n",
    "# Input text:\n",
    "Story title: \"\"\"\n",
    "{title}\n",
    "\"\"\"\n",
    "Comment: \"\"\"\n",
    "{comment}\n",
    "\"\"\"\n",
    "\n",
    "# Output format:\n",
    "Sentiment: your_sentiment\n",
    "Explanation: your_explanation_for_the_sentiment\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get sentiment using OpenAI API\n",
    "def get_sentiment_and_explanation(title, comment):\n",
    "    prompt = prompt_template.format(title=title, comment=comment)\n",
    "\n",
    "    for _ in range(3):  # Retry logic\n",
    "        try:\n",
    "            # Call the OpenAI API\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-4\",  # Choose the appropriate model\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are an expert at analyzing comments.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                max_tokens=150,  # Adjust max tokens if needed\n",
    "                temperature=0.5\n",
    "            )\n",
    "\n",
    "            # Extract the response text\n",
    "            result = response['choices'][0]['message']['content'].strip()\n",
    "\n",
    "            # Extract sentiment and explanation from the response\n",
    "            sentiment_line = next((line for line in result.split('\\n') if \"Sentiment:\" in line), None)\n",
    "            explanation_line = next((line for line in result.split('\\n') if \"Explanation:\" in line), None)\n",
    "\n",
    "            if sentiment_line and explanation_line:\n",
    "                sentiment = int(sentiment_line.split(\":\")[1].strip())\n",
    "                explanation = explanation_line.split(\":\")[1].strip()\n",
    "                return sentiment, explanation\n",
    "            else:\n",
    "                raise ValueError(\"Invalid response format\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"API call failed: {e}. Pausing for 1-2 minutes...\")\n",
    "            time.sleep(random.randint(60, 120))\n",
    "\n",
    "# Function to process comments and save periodically\n",
    "def process_comments(df, output_csv_file, save_interval=20):\n",
    "    for i, row in df.iterrows():\n",
    "        # Skip rows that already have a sentiment and explanation value\n",
    "        if pd.notna(row.get('sentiment')) and pd.notna(row.get('explanation')):\n",
    "            continue\n",
    "\n",
    "        # Perform sentiment analysis and get the explanation\n",
    "        sentiment, explanation = get_sentiment_and_explanation(row['title'], row['comment_text'])\n",
    "        df.at[i, 'sentiment'] = sentiment\n",
    "        df.at[i, 'explanation'] = explanation\n",
    "\n",
    "        # Save progress to CSV after every `save_interval` rows\n",
    "        if (i + 1) % save_interval == 0:\n",
    "            df.to_csv(output_csv_file, index=False)\n",
    "            print(f\"Saved progress at row {i + 1}\")\n",
    "\n",
    "    # Final save at the end of processing\n",
    "    df.to_csv(output_csv_file, index=False)\n",
    "    print(f\"Final result saved to {output_csv_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the CSV file with the Hacker News data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = 'sentiment_385_sampled_cleanup.csv'  # Replace with the actual path to your CSV file\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# If the 'sentiment' and 'explanation' columns don't exist, add them\n",
    "if 'sentiment' not in df.columns:\n",
    "    df['sentiment'] = None\n",
    "if 'explanation' not in df.columns:\n",
    "    df['explanation'] = None\n",
    "\n",
    "# Output file to save the results\n",
    "output_csv_file = 'hackernews_comments_with_sentiment_OPENAI.csv'\n",
    "\n",
    "# Process the comments and periodically save the results\n",
    "process_comments(df, output_csv_file)\n",
    "\n",
    "print(f'Sentiment analysis completed and saved to {output_csv_file}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
