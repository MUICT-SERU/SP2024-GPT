{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1gweCLSmfV3aeUHHXIyn-gVLLUBf03XGE","authorship_tag":"ABX9TyM7Qh/0eEJdNxbDwC6+MUY/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# info"],"metadata":{"id":"d1IvZTeWWbp-"}},{"cell_type":"markdown","source":["This notebook's purpose is to search and retrieve a list of GitHub repository URLs related to AI/LLM topics, to prepare as a control dataset for RQ3 PSM used in causal inference."],"metadata":{"id":"X7sKJLVgWepn"}},{"cell_type":"markdown","source":["# setup"],"metadata":{"id":"oSGOCWX3om7d"}},{"cell_type":"markdown","metadata":{"id":"ZACENGarLFRR"},"source":["## setup paths and load csv"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"R11-QMwSuOLS","executionInfo":{"status":"ok","timestamp":1738125125106,"user_tz":-540,"elapsed":1406,"user":{"displayName":"Prachnachai Meakpaiboonwattana","userId":"17764950184050269979"}}},"outputs":[],"source":["import pandas as pd\n","import requests\n","from datetime import datetime, timedelta\n","import time\n","from urllib.parse import urlparse\n","import os\n","from tqdm.notebook import tqdm"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"-GsXGJtzLIMU","executionInfo":{"status":"ok","timestamp":1738125125108,"user_tz":-540,"elapsed":7,"user":{"displayName":"Prachnachai Meakpaiboonwattana","userId":"17764950184050269979"}}},"outputs":[],"source":["# new version\n","CHECKPOINT_PATH = \"/content/drive/MyDrive/datasets/hn_rq3_treatment/hn_rq3_repos_control_checkpoint_v2.json\"\n","OUTPUT_PATH = \"/content/drive/MyDrive/datasets/hn_rq3_treatment/hn_rq3_repos_control_v2_.csv\"\n","URLS_PATH = \"/content/drive/MyDrive/datasets/hn_rq3_treatment/hn_rq3_repos_control_urls_v2.csv\"\n","# Read the CSV file\n","CHECKPOINT_PATH = \"/content/drive/MyDrive/datasets/hn_rq3_treatment/hn_rq3_repos_control_checkpoint_v2.json\"\n","OUTPUT_PATH = \"/content/drive/MyDrive/datasets/hn_rq3_treatment/hn_rq3_repos_control_v2_.csv\"\n","URLS_PATH = \"/content/drive/MyDrive/datasets/hn_rq3_treatment/hn_rq3_repos_control_urls_v2.csv\"\n"]},{"cell_type":"markdown","metadata":{"id":"iutDWKhDKHsy"},"source":["## setup github api"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"7F_OeHFCYLmi","executionInfo":{"status":"ok","timestamp":1738125126187,"user_tz":-540,"elapsed":1085,"user":{"displayName":"Prachnachai Meakpaiboonwattana","userId":"17764950184050269979"}}},"outputs":[],"source":["from google.colab import userdata\n","GITHUB_TOKEN = userdata.get('GITHUB_TOKEN')"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"IbpQBdupV-vp","executionInfo":{"status":"ok","timestamp":1738125126187,"user_tz":-540,"elapsed":5,"user":{"displayName":"Prachnachai Meakpaiboonwattana","userId":"17764950184050269979"}}},"outputs":[],"source":["# GitHub API authentication\n","if not GITHUB_TOKEN:\n","    raise ValueError(\"Please set GITHUB_TOKEN environment variable\")\n","\n","headers = {\n","    'Authorization': f'token {GITHUB_TOKEN}',\n","    'Accept': 'application/vnd.github.v3+json'\n","}"]},{"cell_type":"markdown","source":["# v5"],"metadata":{"id":"siD9WqmiR7eP"}},{"cell_type":"code","source":["# List of GitHub search queries for AI/ML repositories\n","AI_ML_SEARCH_QUERIES = [\n","    'machine-learning',\n","    'artificial-intelligence',\n","    'deep-learning',\n","    'neural-networks',\n","    'data-science',\n","    'ai',\n","    'ai-research',\n","    'llm',\n","    'transformer',\n","    'openai',\n","    'ml-models',\n","    'pytorch',\n","    'tensorflow',\n","    'scikit-learn',\n","    'keras',\n","    'nlp',\n","    'generative-ai'\n","]\n","\n","def generate_ai_ml_repo_list(\n","    created_date_start: str = '2022-06-01',\n","    created_date_end: str = '2024-06-01',\n","    min_stars: int = 1,\n","    max_stars: int = 50000,\n","    min_forks: int = 1,\n","    total_repos: int = 500\n",") -> list:\n","    \"\"\"\n","    Generate a list of AI/ML GitHub repositories\n","\n","    :param min_forks: Minimum number of forks for a repository\n","    :param total_repos: Total number of repositories to collect\n","    :return: List of GitHub repository URLs\n","    \"\"\"\n","    import requests\n","    import random\n","\n","    # GitHub Search API base URL\n","    base_url = 'https://api.github.com/search/repositories'\n","\n","    # GitHub token for higher rate limits\n","    headers = {\n","        'Accept': 'application/vnd.github.v3+json',\n","        'Authorization': f'token {GITHUB_TOKEN}'\n","    }\n","\n","    ai_ml_repos = set()\n","\n","    # Shuffle queries to get diverse results\n","    random.shuffle(AI_ML_SEARCH_QUERIES)\n","\n","    for query in AI_ML_SEARCH_QUERIES:\n","        # Construct search query\n","        search_query = f'{query} created:{created_date_start}..{created_date_end} stars:{min_stars}..{max_stars} forks:>={min_forks}'\n","\n","        params = {\n","            'q': search_query,\n","            'sort': 'stars',\n","            'order': 'desc',\n","            'per_page': 100  # Max allowed by GitHub API\n","        }\n","\n","        try:\n","            response = requests.get(base_url, headers=headers, params=params)\n","            response.raise_for_status()\n","\n","            # Extract repository URLs\n","            repos = response.json().get('items', [])\n","            for repo in repos:\n","                repo_url = repo['html_url']\n","                ai_ml_repos.add(repo_url)\n","\n","                # Break if we've collected enough repositories\n","                if len(ai_ml_repos) >= total_repos:\n","                    break\n","\n","            # Break outer loop if we've collected enough repositories\n","            if len(ai_ml_repos) >= total_repos:\n","                break\n","\n","        except requests.RequestException as e:\n","            print(f\"Error fetching repositories for query {query}: {e}\")\n","\n","    # Convert to list and truncate if necessary\n","    ai_ml_repos_list = list(ai_ml_repos)[:total_repos]\n","\n","    return ai_ml_repos_list\n"],"metadata":{"id":"m2E_omS0R8Oq","executionInfo":{"status":"ok","timestamp":1738125154529,"user_tz":-540,"elapsed":248,"user":{"displayName":"Prachnachai Meakpaiboonwattana","userId":"17764950184050269979"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Example usage\n","control_repos = generate_ai_ml_repo_list()\n","df = pd.DataFrame({'url': control_repos})\n","df.to_csv(URLS_PATH, index=False)"],"metadata":{"id":"l_otrWhTTpMf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"awYr3ux-WAjv","executionInfo":{"status":"ok","timestamp":1737956845510,"user_tz":-540,"elapsed":10,"user":{"displayName":"Prachnachai Meakpaiboonwattana","userId":"17764950184050269979"}},"outputId":"a13efc24-ef39-4316-f2fc-91ab7da8bf37"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1277"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":[],"metadata":{"id":"l_N6M4gNWKPo"},"execution_count":null,"outputs":[]}]}