{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import statsmodels.formula.api as smf\n",
    "from dowhy import CausalModel\n",
    "from econml.dml import CausalForestDML\n",
    "\n",
    "# Updated function to load and prepare data from the new CSV format\n",
    "def load_and_prepare_data(data_file):\n",
    "    \"\"\"\n",
    "    Load and prepare data from the new CSV format.\n",
    "\n",
    "    Parameters:\n",
    "    data_file: Path to CSV file containing repo metrics\n",
    "\n",
    "    Returns:\n",
    "    DataFrame ready for causal inference\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    df = pd.read_csv(data_file)\n",
    "\n",
    "    # Convert month string to datetime\n",
    "    df['date'] = pd.to_datetime(df['month'])\n",
    "\n",
    "    # Convert HN submission date to datetime\n",
    "    df['submission_date'] = pd.to_datetime(df['hn_submission_date']).dt.tz_localize(None)\n",
    "    print(df[['date', 'submission_date']].dtypes)\n",
    "\n",
    "\n",
    "    # Create treatment indicators\n",
    "    df['hn_submitted'] = df['source'] == 'HN'\n",
    "\n",
    "    # Create post-treatment indicator\n",
    "    df['post_treatment'] = 0\n",
    "    mask = (df['hn_submitted'] == 1) & (df['date'] >= df['submission_date'])\n",
    "    df.loc[mask, 'post_treatment'] = 1\n",
    "\n",
    "    # Create treatment variable\n",
    "    df['treatment'] = df['hn_submitted'] * df['post_treatment']\n",
    "\n",
    "    # Create time period column (months since start)\n",
    "    min_date = df['date'].min()\n",
    "    print(min_date)\n",
    "    df['time_period'] = ((df['date'].dt.year - min_date.year) * 12 +\n",
    "                        (df['date'].dt.month - min_date.month))\n",
    "\n",
    "    # Rename the outcome variables for consistency with the analysis functions\n",
    "    if 'new_prs' in df.columns:\n",
    "        df.rename(columns={'new_prs': 'prs'}, inplace=True)\n",
    "    if 'new_stars' in df.columns:\n",
    "        df.rename(columns={'new_stars': 'stars'}, inplace=True)\n",
    "    if 'new_forks' in df.columns:\n",
    "        df.rename(columns={'new_forks': 'forks'}, inplace=True)\n",
    "    if 'commit_count' in df.columns:\n",
    "        df.rename(columns={'commit_count': 'commits'}, inplace=True)\n",
    "    if 'active_contributors' in df.columns:\n",
    "        df.rename(columns={'active_contributors': 'contributors'}, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Function to match treatment and control repos based on pre-treatment trends\n",
    "def match_control_repos(df, outcome_vars, n_controls_per_treated=5):\n",
    "    \"\"\"\n",
    "    Match treated repos with control repos based on similarity in pre-treatment trends.\n",
    "\n",
    "    Parameters:\n",
    "    df: DataFrame with repo metrics\n",
    "    outcome_vars: List of outcome variables to consider for matching\n",
    "    n_controls_per_treated: Number of control repos to match for each treated repo\n",
    "\n",
    "    Returns:\n",
    "    DataFrame with matched treated and control repos\n",
    "    \"\"\"\n",
    "    # Get list of treated repos\n",
    "    treated_repos = df[df['hn_submitted'] == 1]['repo_url'].unique()\n",
    "\n",
    "    # Get list of potential control repos\n",
    "    control_repos = df[df['hn_submitted'] == 0]['repo_url'].unique()\n",
    "\n",
    "    matched_controls = {}\n",
    "\n",
    "    for treated_repo in treated_repos:\n",
    "        # Get the submission date for this treated repo\n",
    "        submission_date = df[(df['repo_url'] == treated_repo) &\n",
    "                             (df['hn_submitted'] == 1)]['submission_date'].iloc[0]\n",
    "\n",
    "        # Get pre-treatment data for this repo\n",
    "        treated_pre = df[(df['repo_url'] == treated_repo) &\n",
    "                         (df['date'] < submission_date)]\n",
    "\n",
    "        if treated_pre.empty:\n",
    "            continue  # Skip if no pre-treatment data\n",
    "\n",
    "        # Calculate similarity scores with control repos\n",
    "        similarities = []\n",
    "\n",
    "        for control_repo in control_repos:\n",
    "            # Get data for this control repo corresponding to the same time period\n",
    "            control_data = df[(df['repo_url'] == control_repo) &\n",
    "                             (df['date'] < submission_date)]\n",
    "\n",
    "            if control_data.empty:\n",
    "                continue\n",
    "\n",
    "            # Calculate similarity for each outcome variable\n",
    "            sim_scores = []\n",
    "\n",
    "            for var in outcome_vars:\n",
    "                # Check if we have enough data points to calculate similarity\n",
    "                if len(treated_pre) >= 3 and len(control_data) >= 3:\n",
    "                    # Get time series for both repos\n",
    "                    treated_ts = treated_pre.sort_values('date')[var].values\n",
    "                    control_ts = control_data.sort_values('date')[var].values\n",
    "\n",
    "                    # Ensure same length by truncating the longer one\n",
    "                    min_len = min(len(treated_ts), len(control_ts))\n",
    "                    treated_ts = treated_ts[-min_len:]\n",
    "                    control_ts = control_ts[-min_len:]\n",
    "\n",
    "                    # Normalize the time series\n",
    "                    treated_ts = (treated_ts - np.mean(treated_ts)) / (np.std(treated_ts) + 1e-10)\n",
    "                    control_ts = (control_ts - np.mean(control_ts)) / (np.std(control_ts) + 1e-10)\n",
    "\n",
    "                    # Calculate cosine similarity\n",
    "                    sim = cosine_similarity([treated_ts], [control_ts])[0][0]\n",
    "                    sim_scores.append(sim)\n",
    "                else:\n",
    "                    # If not enough data, use a neutral similarity\n",
    "                    sim_scores.append(0)\n",
    "\n",
    "            # Average similarity across all variables\n",
    "            if sim_scores:\n",
    "                avg_sim = np.mean(sim_scores)\n",
    "                similarities.append((control_repo, avg_sim))\n",
    "\n",
    "        # Sort by similarity (highest first) and take top n_controls_per_treated\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        matched_controls[treated_repo] = [repo for repo, _ in similarities[:n_controls_per_treated]]\n",
    "\n",
    "    # Create a new dataframe with treated repos and their matched controls\n",
    "    matched_df = df[df['repo_url'].isin(treated_repos)].copy()\n",
    "\n",
    "    for treated_repo, control_repos_list in matched_controls.items():\n",
    "        for control_repo in control_repos_list:\n",
    "            control_data = df[df['repo_url'] == control_repo].copy()\n",
    "            matched_df = pd.concat([matched_df, control_data])\n",
    "\n",
    "    return matched_df\n",
    "\n",
    "# Function to perform staggered DiD analysis\n",
    "def staggered_did_analysis(df, outcome_var):\n",
    "    \"\"\"\n",
    "    Perform staggered Difference-in-Differences analysis.\n",
    "\n",
    "    Parameters:\n",
    "    df: Prepared DataFrame\n",
    "    outcome_var: Outcome variable to measure\n",
    "\n",
    "    Returns:\n",
    "    Model results\n",
    "    \"\"\"\n",
    "    # Create repo dummies\n",
    "    repo_dummies = pd.get_dummies(df['repo_url'], prefix='repo', drop_first=True)\n",
    "\n",
    "    # Create time period dummies\n",
    "    time_dummies = pd.get_dummies(df['time_period'], prefix='time', drop_first=True)\n",
    "\n",
    "    # Combine with original data\n",
    "    model_df = pd.concat([df[['treatment', outcome_var]], repo_dummies, time_dummies], axis=1)\n",
    "\n",
    "    # Create formula for regression\n",
    "    repo_terms = ' + '.join(repo_dummies.columns)\n",
    "    time_terms = ' + '.join(time_dummies.columns)\n",
    "    formula = f\"{outcome_var} ~ treatment + {repo_terms} + {time_terms}\"\n",
    "\n",
    "    # Run regression\n",
    "    model = smf.ols(formula, data=model_df).fit(cov_type='cluster',\n",
    "                                               cov_kwds={'groups': df['repo_url']})\n",
    "\n",
    "    return model\n",
    "\n",
    "# Perform DiD analysis using DoWhy (keeping this for compatibility)\n",
    "def did_analysis(df, outcome_var='prs'):\n",
    "    \"\"\"\n",
    "    Perform Difference-in-Differences analysis using DoWhy.\n",
    "\n",
    "    Parameters:\n",
    "    df: Prepared DataFrame\n",
    "    outcome_var: Outcome variable to measure\n",
    "\n",
    "    Returns:\n",
    "    Causal effect estimate\n",
    "    \"\"\"\n",
    "    # Define causal graph\n",
    "    graph = \"\"\"\n",
    "    digraph {\n",
    "        time_period -> %s;\n",
    "        repo_url -> %s;\n",
    "        treatment -> %s;\n",
    "        repo_url -> treatment;\n",
    "    }\n",
    "    \"\"\" % (outcome_var, outcome_var, outcome_var)\n",
    "\n",
    "    # Specify variables\n",
    "    treatment_var = \"treatment\"\n",
    "    common_causes = [\"repo_url\", \"time_period\"]\n",
    "\n",
    "    # Create causal model\n",
    "    model = CausalModel(\n",
    "        data=df,\n",
    "        treatment=treatment_var,\n",
    "        outcome=outcome_var,\n",
    "        graph=graph,\n",
    "        common_causes=common_causes\n",
    "    )\n",
    "\n",
    "    # Identify causal effect\n",
    "    identified_estimand = model.identify_effect(proceed_when_unidentifiable=True)\n",
    "\n",
    "    # Estimate causal effect using DiD estimator\n",
    "    estimate = model.estimate_effect(\n",
    "        identified_estimand,\n",
    "        method_name=\"backdoor.econml.dml.DML\",\n",
    "        control_value=0,\n",
    "        treatment_value=1,\n",
    "        target_units=\"att\",  # Average Treatment Effect on the Treated\n",
    "        method_params={\n",
    "            \"init_params\": {\n",
    "                \"model_y\": LassoCV(),\n",
    "                \"model_t\": LassoCV(),\n",
    "                \"model_final\": RandomForestRegressor(n_estimators=100, min_samples_leaf=10),\n",
    "                \"fit_cate_intercept\": False,\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return estimate\n",
    "\n",
    "# Enhanced function to check parallel trends\n",
    "def check_parallel_trends(df, outcome_var='prs', plot_individual_repos=False):\n",
    "    \"\"\"\n",
    "    Check the parallel trends assumption by plotting pre-treatment trends.\n",
    "\n",
    "    Parameters:\n",
    "    df: Prepared DataFrame\n",
    "    outcome_var: Outcome variable to measure\n",
    "    plot_individual_repos: Whether to plot individual repo trends or average\n",
    "    \"\"\"\n",
    "    # Get unique repos that were submitted to HN\n",
    "    hn_repos = df[df['hn_submitted'] == 1]['repo_url'].unique()\n",
    "\n",
    "    # Create a figure\n",
    "    plt.figure(figsize=(14, 8))\n",
    "\n",
    "    # If plotting individual repos\n",
    "    if plot_individual_repos and len(hn_repos) <= 20:  # Limit to 20 repos for clarity\n",
    "        for repo in hn_repos:\n",
    "            # Get data for this repo\n",
    "            repo_data = df[df['repo_url'] == repo]\n",
    "\n",
    "            # Get submission date\n",
    "            submission_date = repo_data['submission_date'].iloc[0]\n",
    "            submission_period = repo_data[\n",
    "                repo_data['date'] == pd.to_datetime(submission_date).replace(day=1)\n",
    "            ]['time_period'].iloc[0]\n",
    "\n",
    "            # Plot pre-treatment trend\n",
    "            pre_treatment = repo_data[repo_data['post_treatment'] == 0]\n",
    "            if not pre_treatment.empty:\n",
    "                plt.plot(pre_treatment['time_period'], pre_treatment[outcome_var], 'b-', alpha=0.3)\n",
    "\n",
    "            # Plot submission point\n",
    "            plt.scatter([submission_period],\n",
    "                       [repo_data[repo_data['time_period'] == submission_period][outcome_var].iloc[0]],\n",
    "                       color='green', marker='o', alpha=0.5)\n",
    "\n",
    "    # Plot average trends\n",
    "    # Filter for pre-treatment periods for HN repos\n",
    "    pre_treatment_all = df[(df['repo_url'].isin(hn_repos)) & (df['post_treatment'] == 0)]\n",
    "    control_group = df[df['hn_submitted'] == 0]\n",
    "\n",
    "    # Aggregate by time period\n",
    "    treated_pre = pre_treatment_all.groupby('time_period')[outcome_var].mean().reset_index()\n",
    "    control_all = control_group.groupby('time_period')[outcome_var].mean().reset_index()\n",
    "\n",
    "    # Plot average trends\n",
    "    plt.plot(treated_pre['time_period'], treated_pre[outcome_var], 'b-',\n",
    "             linewidth=3, label='Pre-treatment (HN Repos)')\n",
    "    plt.plot(control_all['time_period'], control_all[outcome_var], 'r-',\n",
    "             linewidth=3, label='Control (Non-HN Repos)')\n",
    "\n",
    "    # Get the earliest treatment period\n",
    "    min_treatment_period = df[df['post_treatment'] == 1]['time_period'].min()\n",
    "\n",
    "    plt.axvline(x=min_treatment_period, color='green', linestyle='--',\n",
    "                label='First Treatment')\n",
    "    plt.xlabel('Time Period (Months since start)')\n",
    "    plt.ylabel(f'Average {outcome_var}')\n",
    "    plt.title(f'Parallel Trends Check: {outcome_var}')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(f'parallel_trends_{outcome_var}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Enhanced function to visualize treatment effect\n",
    "def visualize_treatment_effect(df, outcome_var='prs'):\n",
    "    \"\"\"\n",
    "    Visualize the treatment effect over time with staggered adoption.\n",
    "\n",
    "    Parameters:\n",
    "    df: Prepared DataFrame\n",
    "    outcome_var: Outcome variable to measure\n",
    "    \"\"\"\n",
    "    # Get unique repos that were submitted to HN\n",
    "    hn_repos = df[df['hn_submitted'] == 1]['repo_url'].unique()\n",
    "\n",
    "    # Create figure\n",
    "    plt.figure(figsize=(16, 9))\n",
    "\n",
    "    # Normalize time relative to treatment\n",
    "    df_treated = df[df['repo_url'].isin(hn_repos)].copy()\n",
    "\n",
    "    # For each treated repo, calculate time relative to its own treatment\n",
    "    relative_time_data = []\n",
    "\n",
    "    for repo in hn_repos:\n",
    "        repo_data = df_treated[df_treated['repo_url'] == repo].copy()\n",
    "\n",
    "        if repo_data.empty or 'submission_date' not in repo_data.columns:\n",
    "            continue\n",
    "\n",
    "        # Get the treatment time period\n",
    "        treatment_date = repo_data['submission_date'].iloc[0]\n",
    "        if pd.isna(treatment_date):\n",
    "            continue\n",
    "\n",
    "        treatment_period = repo_data[\n",
    "            repo_data['date'] == pd.to_datetime(treatment_date).replace(day=1)\n",
    "        ]['time_period'].iloc[0]\n",
    "\n",
    "        # Calculate relative time\n",
    "        repo_data['relative_time'] = repo_data['time_period'] - treatment_period\n",
    "\n",
    "        relative_time_data.append(repo_data)\n",
    "\n",
    "    if relative_time_data:\n",
    "        relative_df = pd.concat(relative_time_data)\n",
    "\n",
    "        # Group by relative time and calculate average\n",
    "        grouped = relative_df.groupby('relative_time')[outcome_var].mean().reset_index()\n",
    "\n",
    "        # Plot\n",
    "        plt.plot(grouped['relative_time'], grouped[outcome_var], 'b-',\n",
    "                linewidth=2, label='Treated Repos (Time Relative to Treatment)')\n",
    "\n",
    "        # Add a vertical line at treatment time (relative_time = 0)\n",
    "        plt.axvline(x=0, color='red', linestyle='--', label='Treatment Time')\n",
    "\n",
    "        # Also plot the control repos average over time for comparison\n",
    "        control_data = df[df['hn_submitted'] == 0].copy()\n",
    "        control_avg = control_data.groupby('time_period')[outcome_var].mean().reset_index()\n",
    "\n",
    "        # Rescale time to center around average treatment time\n",
    "        avg_treatment_time = df_treated[df_treated['post_treatment'] == 1]['time_period'].min()\n",
    "        control_avg['relative_time'] = control_avg['time_period'] - avg_treatment_time\n",
    "\n",
    "        plt.plot(control_avg['relative_time'], control_avg[outcome_var], 'g-',\n",
    "                linewidth=2, label='Control Repos')\n",
    "\n",
    "        plt.xlabel('Months Relative to HN Submission')\n",
    "        plt.ylabel(f'Average {outcome_var}')\n",
    "        plt.title(f'Effect of HackerNews Submission on {outcome_var}')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.savefig(f'staggered_treatment_effect_{outcome_var}.png')\n",
    "\n",
    "    # Also create the traditional visualization\n",
    "    # Aggregate data by time period and treatment status\n",
    "    treatment_data = df[df['hn_submitted'] == 1].copy()\n",
    "    control_data = df[df['hn_submitted'] == 0].copy()\n",
    "\n",
    "    # For repos that were submitted to HN, mark pre and post treatment periods\n",
    "    treatment_pre = treatment_data[treatment_data['post_treatment'] == 0].groupby('time_period')[outcome_var].mean().reset_index()\n",
    "    treatment_post = treatment_data[treatment_data['post_treatment'] == 1].groupby('time_period')[outcome_var].mean().reset_index()\n",
    "    control_all = control_data.groupby('time_period')[outcome_var].mean().reset_index()\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    plt.plot(treatment_pre['time_period'], treatment_pre[outcome_var], 'b-',\n",
    "             label='Pre-treatment (HN Repos)')\n",
    "    plt.plot(treatment_post['time_period'], treatment_post[outcome_var], 'g-',\n",
    "             label='Post-treatment (HN Repos)')\n",
    "    plt.plot(control_all['time_period'], control_all[outcome_var], 'r-',\n",
    "             label='Control (Non-HN Repos)')\n",
    "\n",
    "    # Add a vertical line at the first treatment\n",
    "    first_treatment = treatment_data[treatment_data['post_treatment'] == 1]['time_period'].min()\n",
    "    plt.axvline(x=first_treatment, color='black', linestyle='--',\n",
    "                label='First HN Submission')\n",
    "\n",
    "    plt.xlabel('Time Period (Months since start)')\n",
    "    plt.ylabel(f'Average {outcome_var}')\n",
    "    plt.title(f'Effect of HackerNews Submission on {outcome_var}')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(f'treatment_effect_{outcome_var}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Updated main function\n",
    "def main(data_file):\n",
    "    \"\"\"\n",
    "    Main function to run the causal analysis.\n",
    "\n",
    "    Parameters:\n",
    "    data_file: Path to the data file\n",
    "\n",
    "    Returns:\n",
    "    DataFrame and results\n",
    "    \"\"\"\n",
    "    # Define outcome variables\n",
    "    outcomes = ['stars', 'forks', 'commits', 'prs', 'contributors']\n",
    "\n",
    "    # Load and prepare data\n",
    "    print(\"Loading repo data...\")\n",
    "    all_repos_data = load_and_prepare_data(data_file)\n",
    "\n",
    "    # Check if we have treatment and control repos\n",
    "    n_treated = all_repos_data[all_repos_data['hn_submitted'] == 1]['repo_url'].nunique()\n",
    "    n_control = all_repos_data[all_repos_data['hn_submitted'] == 0]['repo_url'].nunique()\n",
    "\n",
    "    print(f\"Found {n_treated} treated repos and {n_control} control repos\")\n",
    "\n",
    "    # If we don't have control repos, we need to get some from an external source\n",
    "    if n_control == 0:\n",
    "        print(\"No control repos found. Please provide control repos in the dataset.\")\n",
    "        return None, None\n",
    "\n",
    "    # Match treatment and control repos\n",
    "    print(\"Matching treatment and control repos...\")\n",
    "    matched_data = match_control_repos(all_repos_data, outcomes)\n",
    "\n",
    "    # Store results\n",
    "    results = {}\n",
    "\n",
    "    for outcome_var in outcomes:\n",
    "        print(f\"\\nAnalyzing causal effect on {outcome_var}...\")\n",
    "\n",
    "        # Drop NaN values for this specific outcome\n",
    "        analysis_data = matched_data.dropna(subset=[outcome_var])\n",
    "\n",
    "        # Check parallel trends assumption\n",
    "        print(\"Checking parallel trends assumption...\")\n",
    "        check_parallel_trends(analysis_data, outcome_var)\n",
    "\n",
    "        # Run staggered DiD analysis\n",
    "        print(\"Running staggered DiD analysis...\")\n",
    "        model = staggered_did_analysis(analysis_data, outcome_var)\n",
    "\n",
    "        # Calculate DiD estimate (the coefficient of the treatment variable)\n",
    "        did_estimate = model.params['treatment']\n",
    "        did_stderr = model.bse['treatment']\n",
    "        p_value = model.pvalues['treatment']\n",
    "\n",
    "        print(f\"Estimated causal effect on {outcome_var}: {did_estimate:.4f}\")\n",
    "        print(f\"Standard error: {did_stderr:.4f}\")\n",
    "        print(f\"p-value: {p_value:.4f}\")\n",
    "\n",
    "        # Also run the DML estimator from DoWhy for comparison\n",
    "        try:\n",
    "            dowhy_estimate = did_analysis(analysis_data, outcome_var)\n",
    "            print(f\"DoWhy estimated causal effect: {dowhy_estimate.value:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"DoWhy analysis failed: {str(e)}\")\n",
    "            dowhy_estimate = None\n",
    "\n",
    "        # Visualize treatment effect\n",
    "        print(\"Visualizing treatment effect...\")\n",
    "        visualize_treatment_effect(analysis_data, outcome_var)\n",
    "\n",
    "        # Store results\n",
    "        results[outcome_var] = {\n",
    "            'estimate': did_estimate,\n",
    "            'stderr': did_stderr,\n",
    "            'p_value': p_value,\n",
    "            'dowhy_estimate': dowhy_estimate.value if dowhy_estimate else None\n",
    "        }\n",
    "\n",
    "        # Optional: Analyze heterogeneous effects\n",
    "        print(\"Analyzing heterogeneous effects...\")\n",
    "        try:\n",
    "            cf_model, df_with_cate = heterogeneous_effects(analysis_data, outcome_var)\n",
    "\n",
    "            # Save the top and bottom repos by treatment effect\n",
    "            top_repos = df_with_cate.sort_values('cate', ascending=False).head(10)\n",
    "            bottom_repos = df_with_cate.sort_values('cate', ascending=True).head(10)\n",
    "\n",
    "            print(f\"Top 10 repos with highest treatment effect on {outcome_var}:\")\n",
    "            print(top_repos[['repo_url', 'cate']].drop_duplicates('repo_url').head())\n",
    "\n",
    "            print(f\"Bottom 10 repos with lowest treatment effect on {outcome_var}:\")\n",
    "            print(bottom_repos[['repo_url', 'cate']].drop_duplicates('repo_url').head())\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Heterogeneous effects analysis failed: {str(e)}\")\n",
    "\n",
    "    # Summary of results\n",
    "    print(\"\\nSummary of Results:\")\n",
    "    print(\"-\" * 50)\n",
    "    for outcome, result in results.items():\n",
    "        print(f\"Outcome: {outcome}\")\n",
    "        print(f\"  Causal Effect: {result['estimate']:.4f} ± {result['stderr']:.4f}\")\n",
    "        print(f\"  p-value: {result['p_value']:.4f}\")\n",
    "        if result['p_value'] < 0.05:\n",
    "            print(\"  Result is statistically significant at p < 0.05\")\n",
    "        else:\n",
    "            print(\"  Result is not statistically significant at p < 0.05\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    return matched_data, results\n",
    "\n",
    "# Call this function with your data file path\n",
    "# matched_data, results = main(\"your_data_file.csv\")\n",
    "\n",
    "# Function to select optimal control repos by examining pre-treatment trends\n",
    "def select_optimal_controls(df, outcome_vars, max_controls=500):\n",
    "    \"\"\"\n",
    "    Select optimal control repos that best satisfy the parallel trends assumption.\n",
    "\n",
    "    Parameters:\n",
    "    df: DataFrame with repo metrics\n",
    "    outcome_vars: List of outcome variables to consider\n",
    "    max_controls: Maximum number of control repos to select\n",
    "\n",
    "    Returns:\n",
    "    List of optimal control repo URLs\n",
    "    \"\"\"\n",
    "    # Get all treated repos\n",
    "    treated_repos = df[df['hn_submitted'] == 1]['repo_url'].unique()\n",
    "\n",
    "    # Get all potential control repos\n",
    "    potential_controls = df[df['hn_submitted'] == 0]['repo_url'].unique()\n",
    "\n",
    "    # If we have no potential controls, return an empty list\n",
    "    if len(potential_controls) == 0:\n",
    "        return []\n",
    "\n",
    "    # For each time period, calculate the average of each outcome variable for treated repos\n",
    "    treated_avgs = {}\n",
    "    for var in outcome_vars:\n",
    "        treated_avgs[var] = df[df['hn_submitted'] == 1].groupby('time_period')[var].mean()\n",
    "\n",
    "    # Calculate how well each potential control repo's pre-treatment trend matches the treated repos\n",
    "    control_scores = []\n",
    "\n",
    "    for control_repo in potential_controls:\n",
    "        control_data = df[df['repo_url'] == control_repo]\n",
    "\n",
    "        score = 0\n",
    "        for var in outcome_vars:\n",
    "            # Get the control repo's values\n",
    "            control_values = control_data.set_index('time_period')[var]\n",
    "\n",
    "            # Calculate score based on how well it matches the treated repos' average\n",
    "            # (only for time periods where both have data)\n",
    "            common_periods = treated_avgs[var].index.intersection(control_values.index)\n",
    "\n",
    "            if len(common_periods) > 2:  # Need at least 3 points to evaluate trend\n",
    "                treated_vals = treated_avgs[var].loc[common_periods].values\n",
    "                control_vals = control_values.loc[common_periods].values\n",
    "\n",
    "                # Normalize to account for scale differences\n",
    "                treated_norm = (treated_vals - np.mean(treated_vals)) / (np.std(treated_vals) + 1e-10)\n",
    "                control_norm = (control_vals - np.mean(control_vals)) / (np.std(control_vals) + 1e-10)\n",
    "\n",
    "                # Calculate correlation (how well the trends match)\n",
    "                if np.std(treated_norm) > 0 and np.std(control_norm) > 0:\n",
    "                    corr = np.corrcoef(treated_norm, control_norm)[0, 1]\n",
    "                    score += corr\n",
    "\n",
    "        # Average the score across all outcome variables\n",
    "        if len(outcome_vars) > 0:\n",
    "            score /= len(outcome_vars)\n",
    "            control_scores.append((control_repo, score))\n",
    "\n",
    "    # Sort by score (higher is better)\n",
    "    control_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Return the top control repos\n",
    "    return [repo for repo, _ in control_scores[:max_controls]]\n",
    "\n",
    "# Function to heterogeneous treatment effects - keeping this from original\n",
    "def heterogeneous_effects(df, outcome_var='prs'):\n",
    "    \"\"\"\n",
    "    Analyze heterogeneous treatment effects using CausalForest.\n",
    "\n",
    "    Parameters:\n",
    "    df: Prepared DataFrame\n",
    "    outcome_var: Outcome variable to measure\n",
    "\n",
    "    Returns:\n",
    "    CausalForest model and DataFrame with CATE estimates\n",
    "    \"\"\"\n",
    "    # Select numeric features (excluding the outcome and treatment variables)\n",
    "    feature_cols = [col for col in df.columns if df[col].dtype in [np.int64, np.float64]]\n",
    "    feature_cols = [col for col in feature_cols if col not in\n",
    "                    [outcome_var, 'treatment', 'hn_submitted', 'post_treatment']]\n",
    "\n",
    "    # Prepare features\n",
    "    features = df[feature_cols]\n",
    "    treatment = df['treatment']\n",
    "    outcome = df[outcome_var]\n",
    "\n",
    "    # Drop rows with NaN values\n",
    "    mask = ~(features.isna().any(axis=1) | treatment.isna() | outcome.isna())\n",
    "    features = features[mask]\n",
    "    treatment = treatment[mask]\n",
    "    outcome = outcome[mask]\n",
    "\n",
    "    # Convert to numpy arrays and ensure correct shape\n",
    "    features = features.values\n",
    "    treatment = treatment.values.ravel()  # Use ravel() to ensure 1D array\n",
    "    outcome = outcome.values.ravel()      # Use ravel() to ensure 1D array\n",
    "\n",
    "    # Fit causal forest model\n",
    "    cf_model = CausalForestDML(\n",
    "        model_y=LassoCV(),  # Will use default models\n",
    "        model_t=LassoCV(),\n",
    "        n_estimators=100,\n",
    "        min_samples_leaf=10,\n",
    "        fit_cate_intercept=False,\n",
    "    )\n",
    "    cf_model.fit(features, treatment, outcome)\n",
    "\n",
    "    # Calculate conditional treatment effects\n",
    "    cate_estimates = cf_model.effect(features)\n",
    "\n",
    "    # Add CATE estimates to DataFrame\n",
    "    df_with_cate = df[mask].copy()\n",
    "    df_with_cate['cate'] = cate_estimates\n",
    "\n",
    "    return cf_model, df_with_cate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading repo data...\n",
      "date               datetime64[ns]\n",
      "submission_date    datetime64[ns]\n",
      "dtype: object\n",
      "2022-05-01 00:00:00\n",
      "Found 1814 treated repos and 0 control repos\n",
      "No control repos found. Please provide control repos in the dataset.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m matched_data, results = main(\u001b[33m\"\u001b[39m\u001b[33m./hn-stories-gh-ai-metrics.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Review the results\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m outcome, result \u001b[38;5;129;01min\u001b[39;00m \u001b[43mresults\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m():\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOutcome: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutcome\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Causal Effect: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[33m'\u001b[39m\u001b[33mestimate\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ± \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[33m'\u001b[39m\u001b[33mstderr\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "# Load your dataset\n",
    "matched_data, results = main(\"./hn-stories-gh-ai-metrics.csv\")\n",
    "\n",
    "# Review the results\n",
    "for outcome, result in results.items():\n",
    "    print(f\"Outcome: {outcome}\")\n",
    "    print(f\"  Causal Effect: {result['estimate']:.4f} ± {result['stderr']:.4f}\")\n",
    "    print(f\"  p-value: {result['p_value']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "naist-2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
