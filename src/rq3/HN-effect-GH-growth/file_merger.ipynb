{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df_path = '../dataset/sentiments_df.csv'\n",
    "metrics_df_path = '../dataset/hn-stories-gh-ai-metrics-5months-[no-dupes]-v4-monthly-new.csv','join_result.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the sentiment dataset and the GitHub metrics dataset together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load CSV files\n",
    "def load_csv_file(filePath):\n",
    "    df = pd.read_csv(filePath)\n",
    "    df = df.drop_duplicates(subset=['discussion_id']) #Remove duplicated stories\n",
    "    #print(df)\n",
    "    return df\n",
    "\n",
    "def file_merger(sentiment_df_path,metric_df_path,output_file):\n",
    "    senti_df = load_csv_file(sentiment_df_path)\n",
    "    senti_df = senti_df[['discussion_id','average_comments_sentiment','overall_comments_sentiment','url']]\n",
    "    print('sentiment_df stories: ' + str(len(senti_df)))\n",
    "    print('sentiment_df stories with comment: ' + str(len(senti_df[(senti_df != -2).all(1)])))\n",
    "    print('sentiment_df stories (no dupe): ' + str(len(senti_df.sort_values('average_comments_sentiment', ascending=False).drop_duplicates(subset=['url'], keep='first'))))\n",
    "\n",
    "    senti_df = senti_df.sort_values('average_comments_sentiment', ascending=False).drop_duplicates(subset=['url'], keep='first')\n",
    "    senti_df = senti_df[(senti_df != -2).all(1)]\n",
    "    print('sentiment_df stories with comment (no dupe): ' + str(len(senti_df)))\n",
    "\n",
    "    metric_df = load_csv_file(metric_df_path)\n",
    "    print('metric_df stories: ' + str(len(metric_df)))\n",
    "\n",
    "    join_df = metric_df.merge(senti_df.set_index('url'), on='url', how='inner')\n",
    "    print('After join: ' + str(len(join_df)))\n",
    "\n",
    "    join_df = join_df[(join_df != -2).all(1)]\n",
    "    print('Remove stories with no comment: ' + str(len(join_df)))\n",
    "\n",
    "    join_df.to_csv(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment_df stories: 2194\n",
      "sentiment_df stories with comment: 1003\n",
      "sentiment_df stories (no dupe): 1813\n",
      "sentiment_df stories with comment (no dupe): 934\n",
      "metric_df stories: 1813\n",
      "After join: 934\n",
      "Remove stories with no comment: 934\n"
     ]
    }
   ],
   "source": [
    "file_merger(sentiment_df_path,metrics_df_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
