{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scikit_posthocs import posthoc_dunn\n",
    "from statannotations.Annotator import Annotator\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find average sentiment of comments in each HN story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_comments_sentiment(df_comments,df_stories):\n",
    "    return df_comments.groupby('story_id')['comment_sentiment'].mean()\n",
    "\n",
    "comments = pd.read_csv('hn_gh_ai_comment_sentiment.csv')\n",
    "stories = pd.read_csv('hn_gh_ai_story_sentiment.csv')\n",
    "average = average_comments_sentiment(comments,stories)\n",
    "\n",
    "print('unique story ids in hn_gh_ai_story_sentiment.csv: ' + str(len(stories)))\n",
    "print('unique story ids in hn_gh_ai_comment_sentiment.csv: ' + str(len(average)))\n",
    "\n",
    "\n",
    "average_sentiments = []\n",
    "for i in stories['discussion_id']:\n",
    "    if average.get(i) != None:\n",
    "        average_sentiments.append(average.get(i))\n",
    "    else:\n",
    "        average_sentiments.append(-2)\n",
    "\n",
    "stories['average_comments_sentiment'] = average_sentiments\n",
    "stories['overall_comments_sentiment'] = stories['average_comments_sentiment'].apply(lambda x: -2 if x < -1 else(-1 if x < -0.5 else( 1 if x > 0.5 else 0)))\n",
    "stories.to_csv('sentiments_v3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for loading and categorizing csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load CSV files\n",
    "def load_csv_file(filePath):\n",
    "    df = pd.read_csv(filePath)\n",
    "    df = df.drop_duplicates(subset=['discussion_id']) #Remove duplicated stories\n",
    "    #print(df)\n",
    "    return df\n",
    "\n",
    "#Categorize sentiment groups and save them into separate files\n",
    "\n",
    "def categorizer(df, save_to_file = True):\n",
    "    neg = df[df['overall_comments_sentiment'] == -1]\n",
    "    neu = df[df['overall_comments_sentiment'] == 0]\n",
    "    pos = df[df['overall_comments_sentiment'] == 1]\n",
    "    print('Categorize result:')\n",
    "    print(f\"Negative: {len(neg)}\")\n",
    "    print(f\"Neutral: {len(neu)}\")\n",
    "    print(f\"Positive: {len(pos)}\")\n",
    "    print(f\"Total: {len(df)}\")\n",
    "\n",
    "    if save_to_file:\n",
    "        pos.to_csv('Positive_stories.csv', index=False)\n",
    "        neu.to_csv('Neutral_stories.csv', index=False)\n",
    "        neg.to_csv('Negative_stories.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join sentiment file and GitHub metrics file and categorize them based on sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti_df = load_csv_file('sentiments_v3.csv')\n",
    "senti_df = senti_df[['discussion_id','average_comments_sentiment','overall_comments_sentiment','url']]\n",
    "print('sentiment_df stories: ' + str(len(senti_df)))\n",
    "print('sentiment_df stories with comment: ' + str(len(senti_df[(senti_df != -2).all(1)])))\n",
    "print('sentiment_df stories (no dupe): ' + str(len(senti_df.sort_values('average_comments_sentiment', ascending=False).drop_duplicates(subset=['url'], keep='first'))))\n",
    "\n",
    "senti_df = senti_df.sort_values('average_comments_sentiment', ascending=False).drop_duplicates(subset=['url'], keep='first')\n",
    "senti_df = senti_df[(senti_df != -2).all(1)]\n",
    "print('sentiment_df stories with comment (no dupe): ' + str(len(senti_df)))\n",
    "\n",
    "metric_df = load_csv_file('hn-stories-gh-ai-metrics-5months-[no-dupes]-v4-monthly-new.csv')\n",
    "print('metric_df stories: ' + str(len(metric_df)))\n",
    "\n",
    "join_df = metric_df.merge(senti_df.set_index('url'), on='url', how='inner')\n",
    "print('After join: ' + str(len(join_df)))\n",
    "\n",
    "join_df = join_df[(join_df != -2).all(1)]\n",
    "print('Remove stories with no comment: ' + str(len(join_df)))\n",
    "\n",
    "join_df.to_csv('join_result-v4.csv', index=False)\n",
    "#join_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate distance of a metric between 2 time periods\n",
    "def calculate_dist(df, value1, value2):\n",
    "    return df[value2] - df[value1]\n",
    "\n",
    "#Create a column for distance of metric\n",
    "def create_dist(df, value1, value2, result_name):\n",
    "    df[result_name] = calculate_dist(df, value1, value2)\n",
    "\n",
    "#Calculate percent change of a metric between 2 time periods\n",
    "def calculate_percentage(df,value1,value2):\n",
    "    return ((df[value2]/df[value1]) * 100) - 100 \n",
    "\n",
    "#Create a column for percent change of metric\n",
    "def create_percentage(df,value1,value2, result_name):\n",
    "    percent_result = calculate_percentage(df,value1,value2)\n",
    "    #Replace inf value with 0\n",
    "    percent_result.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    percent_result.fillna(0, inplace=True)\n",
    "    df[result_name] = percent_result.apply(\n",
    "        lambda x: 0 if x == np.nan else x\n",
    "    )\n",
    "\n",
    "#Run all function above for all metrics\n",
    "def create_dist_percent(df,period1, period2):\n",
    "    create_dist(df, 'commits_' + period1, 'commits_' + period2, 'dist_commits(' + period1 + '-'+period2+')')\n",
    "    create_dist(df, 'pull_requests_' + period1, 'pull_requests_'+ period2, 'dist_pull_requests(' + period1 + '-'+period2+')')\n",
    "    create_dist(df, 'stars_' + period1, 'stars_'+ period2, 'dist_stars(' + period1 + '-'+period2+')')\n",
    "    create_dist(df, 'forks_' + period1, 'forks_'+ period2, 'dist_forks(' + period1 + '-'+period2+')')\n",
    "    create_dist(df, 'contributors_' + period1, 'contributors_'+ period2, 'dist_contributors(' + period1 + '-'+period2+')')\n",
    "    create_percentage(df, 'commits_'+period1, 'commits_'+ period2, 'percent_commits(' + period1 + '-'+period2+')')\n",
    "    create_percentage(df, 'pull_requests_'+period1, 'pull_requests_'+ period2, 'percent_pull_requests(' + period1 + '-'+period2+')')\n",
    "    create_percentage(df, 'stars_'+period1, 'stars_'+ period2, 'percent_stars(' + period1 + '-'+period2+')')\n",
    "    create_percentage(df, 'forks_'+period1, 'forks_'+ period2, 'percent_forks(' + period1 + '-'+period2+')')\n",
    "    create_percentage(df, 'contributors_'+period1, 'contributors_'+ period2, 'percent_contributors(' + period1 + '-'+period2+')')\n",
    "\n",
    "#Accumulate metric value between each month\n",
    "def accumulate_metrics(df,metric_of_interest, amount_of_months):\n",
    "    for j in df['url']:\n",
    "        cumulative_value = df.loc[df['url'] == j,metric_of_interest + '_at_submission']\n",
    "        for i in range(1, amount_of_months+1):\n",
    "            cumulative_value += df[metric_of_interest + '_month_' +str(i)]\n",
    "            df.loc[df['url'] == j,metric_of_interest + '_month_' +str(i)] = cumulative_value\n",
    "    df.to_csv('join_result-v4.csv', index=False)\n",
    "\n",
    "#Accumulate all metric value between each month\n",
    "def accumulate_all_metrics(df, amount_of_months):\n",
    "    accumulate_metrics(df,'stars',amount_of_months)\n",
    "    accumulate_metrics(df,'forks',amount_of_months)\n",
    "    accumulate_metrics(df,'commits',amount_of_months)\n",
    "    accumulate_metrics(df,'pull_requests',amount_of_months)\n",
    "    accumulate_metrics(df,'contributors',amount_of_months)\n",
    "\n",
    "create_dist_percent(join_df,'at_submission','month_1')\n",
    "create_dist_percent(join_df,'month_1','month_2')\n",
    "create_dist_percent(join_df,'month_2','month_3')\n",
    "create_dist_percent(join_df,'month_3','month_4')\n",
    "create_dist_percent(join_df,'month_4','month_5')\n",
    "\n",
    "accumulate_all_metrics(join_df,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add sentiment column which use 'Positive, Neutral, Negative' for classification (Original sentiment value use '1,0,-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_df['sentiment'] = join_df['overall_comments_sentiment'].apply(\n",
    "        lambda x: 'Positve' if x == 1 else ('Neutral' if x == 0 else 'Negative')\n",
    "    )\n",
    "\n",
    "categorizer(join_df)\n",
    "pos = pd.read_csv('Positive_stories.csv')\n",
    "neu = pd.read_csv('Neutral_stories.csv')\n",
    "neg = pd.read_csv('Negative_stories.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate and display means of metric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metric_mean(df,metric_of_interest):\n",
    "    result = []\n",
    "    result.append(df[metric_of_interest+'_at_submission'].mean())\n",
    "    for i in range(1,6):\n",
    "        result.append(df[metric_of_interest+'_month_'+str(i)].mean())\n",
    "    return result\n",
    "\n",
    "def display_metric_mean(df,metric_of_interest):\n",
    "    print('Mean of ' + metric_of_interest + ' each month:')\n",
    "    #print('  Submission: %.3f' % df[metric_of_interest + '_at_submission'].mean())\n",
    "    for i in range(1,6):\n",
    "        print('  Month ' + str(i) + ': %.3f' % df[metric_of_interest+'_month_'+str(i)].mean())\n",
    "\n",
    "def display_all_metric_mean(df):\n",
    "    display_metric_mean(df,'commits')\n",
    "    display_metric_mean(df,'contributors')\n",
    "    display_metric_mean(df,'stars')\n",
    "    display_metric_mean(df,'forks')\n",
    "    display_metric_mean(df,'pull_requests')\n",
    "\n",
    "print('Positive Group')\n",
    "display_all_metric_mean(pos)\n",
    "print('\\nNeutral Group')\n",
    "display_all_metric_mean(neu)\n",
    "print('\\nNegative Group')\n",
    "display_all_metric_mean(neg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display seaborn plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sns_box_plot(df, metric_of_interest, save = False):\n",
    "    #Melt data\n",
    "    mdf = pd.melt(df,id_vars=['url'], value_name='distance',value_vars=[metric_of_interest+'_month_1', metric_of_interest+'_month_2', metric_of_interest+'_month_3', metric_of_interest+'_month_4', metric_of_interest+'_month_5'])\n",
    "    mdf['variable'] = mdf['variable'].apply(\n",
    "        lambda x: 'm 1' if x == metric_of_interest+'_month_1' else ('m 2' if x == metric_of_interest+'_month_2' else ('m 3' if x==metric_of_interest+'_month_3' else ('m 4' if x == metric_of_interest+'_month_4' else 'm 5')))\n",
    "    )\n",
    "    senti_df = df[['url','sentiment']]\n",
    "    mdf = mdf.join(senti_df.set_index('url'), on='url')\n",
    "    mdf = mdf.drop('url', axis=1)\n",
    "\n",
    "    ax = sns.boxplot(x=mdf['variable'], y=mdf['distance'], hue=mdf['sentiment'], native_scale=True, palette=[ 'skyblue', 'lightgreen', 'tomato'], showfliers=False, showmeans=True)\n",
    "    ax = sns.pointplot(x=mdf['variable'], y=mdf['distance'], hue=mdf['sentiment'],dodge=.55 , errorbar=None,palette=['skyblue', 'lightgreen',  'tomato'], ax=ax)\n",
    "    ax.set_xlabel(None)\n",
    "    ax.set_ylabel(None)\n",
    "    ax.legend([], [], frameon=False)\n",
    "    plt.title(None)\n",
    "    if save:\n",
    "        plt.savefig(metric_of_interest+'.pdf')\n",
    "    plt.show()\n",
    "\n",
    "def display_plot_all(save = False):\n",
    "    sns_box_plot(join_df,'commits', save=save)\n",
    "    sns_box_plot(join_df,'pull_requests', save=save)\n",
    "    sns_box_plot(join_df,'stars',save=save)\n",
    "    sns_box_plot(join_df,'forks',save=save)\n",
    "    sns_box_plot(join_df,'contributors',save=save)\n",
    "\n",
    "display_plot_all(save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unused codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Kruskal Wallis test v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kruskal_test(pos_group, neu_group, neg_group, metric_of_interest, print_result = True, return_value=False):\n",
    "    pos_group = pos_group[metric_of_interest]\n",
    "    neu_group = neu_group[metric_of_interest]\n",
    "    neg_group = neg_group[metric_of_interest]\n",
    "    statistic, p_value = stats.kruskal(pos_group,neu_group,neg_group)\n",
    "    reject_null =  p_value < 0.05\n",
    "\n",
    "    if print_result:\n",
    "        print('Result of statistical on ' + metric_of_interest + \":\")\n",
    "        print(f\"Statistic result: {statistic}\")\n",
    "        print(f\"p-value: {p_value}\")\n",
    "        if reject_null:\n",
    "            print(\"< alpha(0.05): True\\n\" )\n",
    "        else:\n",
    "            print(\"< alpha(0.05): False\\n\")\n",
    "\n",
    "    if return_value:\n",
    "        return{\n",
    "            'statistic': statistic,\n",
    "            'p_value': p_value\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_molten(df,metric_of_interest,group):\n",
    "    dunn_df = posthoc_dunn(\n",
    "        df, val_col=metric_of_interest, group_col=group, p_adjust='fdr_bh'\n",
    "    )\n",
    "\n",
    "    remove = np.tril(np.ones(dunn_df.shape), k=0).astype(\"bool\")\n",
    "    dunn_df[remove] = np.nan\n",
    "    molten_df = dunn_df.melt(ignore_index=False).reset_index().dropna()\n",
    "\n",
    "    return molten_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply to statistical test to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sns_box_plot_statistical(df, metric_of_interest, month_amount = ' (1 month)'):\n",
    "    ax = sns.boxplot(x=df[\"sentiment\"], y=df[metric_of_interest], native_scale=True, palette=['lightgreen', 'skyblue', 'tomato'], showfliers=False)\n",
    "    plt.title(metric_of_interest + ' after HN submission' + month_amount)\n",
    "\n",
    "    molten_df = get_molten(df,metric_of_interest,'sentiment')\n",
    "    pairs = [(i[1][\"index\"], i[1][\"variable\"]) for i in molten_df.iterrows()]\n",
    "    p_values = [i[1][\"value\"] for i in molten_df.iterrows()]\n",
    "\n",
    "    annotator = Annotator(\n",
    "        ax, pairs, data=df, x=\"sentiment\", y=metric_of_interest\n",
    "    )\n",
    "\n",
    "    annotator.configure(text_format=\"star\",loc=\"inside\")\n",
    "    annotator.set_pvalues_and_annotate(p_values)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "sns_box_plot_statistical(join_df,\"percent_commits\")\n",
    "sns_box_plot_statistical(join_df,\"percent_forks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display plot (Non-sns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_plot(pos_,neu_,neg_, metric_of_interest):\n",
    "    senti_groups = [pos_[metric_of_interest],neu_[metric_of_interest],neg_[metric_of_interest]]\n",
    "\n",
    "    labels = ['Positive', 'Neutral', 'Negative']\n",
    "    colors = ['lightgreen', 'skyblue', 'tomato']\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.suptitle( metric_of_interest + ' after HN submission')\n",
    "    ax.set_ylabel(metric_of_interest)\n",
    "\n",
    "    bplot = ax.boxplot(senti_groups,\n",
    "                   patch_artist=True,  # fill with color\n",
    "                   tick_labels=labels)  # will be used to label x-ticks\n",
    "\n",
    "    # fill with colors\n",
    "    for patch, color in zip(bplot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normality Test (Shapiro-Wilk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_normality(data):\n",
    "    statistic, p_value = stats.shapiro(data)\n",
    "    #print(\"Normality Test Results:\")\n",
    "    print(f\"Is normal distribution? {'Yes' if p_value > 0.05 else 'No'}\")\n",
    "    print(f\"P-value: {p_value}\\n\")\n",
    "    return {\n",
    "        'statistic': statistic,\n",
    "        'p_value': p_value,\n",
    "        'is_normal': p_value > 0.05\n",
    "    }\n",
    "\n",
    "#rng = np.random.default_rng()\n",
    "#x = stats.norm.rvs(loc=5, scale=3, size=100, random_state=rng)\n",
    "\n",
    "print(\"Normality test for stars\")\n",
    "normality_result = test_normality(join_df['stars'])\n",
    "print(\"Normality test for forks\")\n",
    "normality_result = test_normality(join_df['forks'])\n",
    "print(\"Normality test for total_commits\")\n",
    "normality_result = test_normality(join_df['total_commits'])\n",
    "print(\"Normality test for total_issues\")\n",
    "normality_result = test_normality(join_df['total_issues'])\n",
    "print(\"Normality test for total_contributors\")\n",
    "normality_result = test_normality(join_df['total_contributors'])\n",
    "print(\"Normality test for total_prs\")\n",
    "normality_result = test_normality(join_df['total_prs'])\n",
    "print(\"Normality test for pr_contributors\")\n",
    "normality_result = test_normality(join_df['pr_contributors'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old pyplot code to display frequency on raw metric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(metric_of_interest):\n",
    "    fig, axs = plt.subplots(sharey=True, tight_layout=True)\n",
    "    axs.hist(join_df[metric_of_interest], bins=100)\n",
    "    fig.suptitle(metric_of_interest)\n",
    "    plt.show()\n",
    "\n",
    "plot_distribution('stars')\n",
    "plot_distribution('forks')\n",
    "plot_distribution('total_commits')\n",
    "plot_distribution('total_issues')\n",
    "plot_distribution('total_contributors')\n",
    "plot_distribution('total_prs')\n",
    "plot_distribution('pr_contributors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical test function (Kruskal Wallis H Test) V1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical tests between 3 sentiment groups (positive, neutral, negative) on each GitHub metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = pd.read_csv('Positive_stories.csv')\n",
    "neu = pd.read_csv('Neutral_stories.csv')\n",
    "neg = pd.read_csv('Negative_stories.csv')\n",
    "\n",
    "#print(stats.kruskal(pos['stars'],neu['stars'],neg['stars']))\n",
    "\n",
    "Kruskal_test(pos,neu,neg,'stars')\n",
    "Kruskal_test(pos,neu,neg,'forks')\n",
    "Kruskal_test(pos,neu,neg,'total_commits')\n",
    "Kruskal_test(pos,neu,neg,'total_issues')\n",
    "Kruskal_test(pos,neu,neg,'total_prs')\n",
    "Kruskal_test(pos,neu,neg,'total_contributors')\n",
    "Kruskal_test(pos,neu,neg,'pr_contributors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display plot of repos frequency on raw metric values with sentiment grouping v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(pos, neu, neg, metric_of_interest):\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=2)\n",
    "    axs[0,0].hist(pos[metric_of_interest], facecolor='g',alpha=0.75)\n",
    "    axs[0, 0].set_title('Positive')\n",
    "    axs[0,1].hist(neu[metric_of_interest], facecolor='b',alpha=0.75)\n",
    "    axs[0, 1].set_title('Neutral')\n",
    "    axs[1,0].hist(neg[metric_of_interest], facecolor='r', alpha=0.75)\n",
    "    axs[1,0].set_title('Negative')\n",
    "\n",
    "    fig.suptitle(metric_of_interest)\n",
    "    fig.tight_layout(pad=1.1)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display plot of repos frequency on raw metric values with sentiment grouping v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(pos, neu, neg, metric_of_interest):\n",
    "    metric = [\n",
    "        pos[metric_of_interest],\n",
    "        neu[metric_of_interest],\n",
    "        neg[metric_of_interest]\n",
    "    ]\n",
    "    labels = ['Positive', 'Neutral', 'Negative']\n",
    "    colors = ['lightgreen', 'skyblue', 'coral']\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_ylabel(metric_of_interest)\n",
    "\n",
    "    bplot = ax.boxplot(metric,patch_artist=True,  tick_labels=labels)\n",
    "\n",
    "# fill with colors\n",
    "    for patch, color in zip(bplot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(pos,neu,neg, 'stars')\n",
    "plot_metric(pos,neu,neg, 'forks')\n",
    "plot_metric(pos,neu,neg, 'total_commits')\n",
    "plot_metric(pos,neu,neg, 'total_issues')\n",
    "plot_metric(pos,neu,neg, 'total_contributors')\n",
    "plot_metric(pos,neu,neg,'total_prs')\n",
    "plot_metric(pos,neu,neg,'pr_contributors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANOSIM test example\n",
    "\n",
    "import numpy as np\n",
    "from skbio.stats.distance import anosim\n",
    "from skbio.stats.distance import DistanceMatrix\n",
    "from skbio import io\n",
    "\n",
    "# Example data: distance matrix and grouping (labels) for samples\n",
    "# The distance matrix is a square matrix where the element at [i, j] is the distance between sample i and sample j\n",
    "distance_data = np.array([\n",
    "    [0.0, 1.0, 0.5, 1.5],\n",
    "    [1.0, 0.0, 1.2, 1.8],\n",
    "    [0.5, 1.2, 0.0, 1.3],\n",
    "    [1.5, 1.8, 1.3, 0.0]\n",
    "])\n",
    "\n",
    "# Labels for grouping of the samples\n",
    "labels = ['Group1', 'Group1', 'Group2', 'Group2']\n",
    "\n",
    "# Create a DistanceMatrix object from the distance matrix\n",
    "dist_matrix = DistanceMatrix(distance_data, ids=['Sample1', 'Sample2', 'Sample3', 'Sample4'])\n",
    "\n",
    "# Perform ANOSIM test\n",
    "anosim_result = anosim(dist_matrix, labels)\n",
    "\n",
    "# Output the ANOSIM result\n",
    "print(anosim_result)\n",
    "#print(\"ANOSIM Statistic (R):\", anosim_result.statistic)\n",
    "#print(\"p-value:\", anosim_result.p_value)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
