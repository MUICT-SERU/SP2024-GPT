{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving GitHub Metrics for each discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "from urllib.parse import urlparse\n",
    "from tqdm.notebook import tqdm\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "# GitHub API credentials\n",
    "GITHUB_TOKEN = os.environ.get(\"GITHUB_TOKEN\")\n",
    "HEADERS = {'Authorization': f'token {GITHUB_TOKEN}'}\n",
    "print(GITHUB_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "INPUT_CSV = '../../data/hn_stories_dataset_gh_final.csv'\n",
    "OUTPUT_JSON = '../../data/hn_gh.csv'\n",
    "PROGRESS_FILE = 'progress.json'\n",
    "ERROR_LOG = 'error_log.txt'\n",
    "\n",
    "# Maximum number of retries\n",
    "MAX_RETRIES = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_github_repo_url(url):\n",
    "    \"\"\"Check if the URL is a valid GitHub repository URL.\"\"\"\n",
    "    parsed = urlparse(url)\n",
    "    return parsed.netloc == 'github.com' and len(parsed.path.split('/')) == 3\n",
    "\n",
    "def get_repo_stats(owner, repo):\n",
    "    \"\"\"Retrieve star and fork history for a repository.\"\"\"\n",
    "    stars_url = f'https://api.github.com/repos/{owner}/{repo}/stargazers'\n",
    "    forks_url = f'https://api.github.com/repos/{owner}/{repo}/forks'\n",
    "\n",
    "    stars_history = []\n",
    "    forks_history = []\n",
    "\n",
    "    for url in [stars_url, forks_url]:\n",
    "        page = 1\n",
    "        while True:\n",
    "            response = requests.get(f'{url}?page={page}&per_page=100', headers=HEADERS)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                if not data:\n",
    "                    break\n",
    "                for item in data:\n",
    "                    timestamp = datetime.strptime(item['starred_at'] if 'starred_at' in item else item['created_at'], '%Y-%m-%dT%H:%M:%SZ').timestamp()\n",
    "                    if 'starred_at' in item:\n",
    "                        stars_history.append((timestamp, page * 100 + len(stars_history) + 1))\n",
    "                    else:\n",
    "                        forks_history.append((timestamp, page * 100 + len(forks_history) + 1))\n",
    "                page += 1\n",
    "            elif response.status_code == 403:\n",
    "                reset_time = int(response.headers.get('X-RateLimit-Reset', 0))\n",
    "                sleep_time = max(reset_time - time.time(), 0) + 1\n",
    "                raise Exception(f\"Rate limit exceeded. Need to sleep for {sleep_time} seconds.\")\n",
    "            else:\n",
    "                raise Exception(f\"HTTP Error: {response.status_code}, {response.text}\")\n",
    "\n",
    "    return {'stars_history': stars_history, 'forks_history': forks_history}\n",
    "\n",
    "def log_error(url, error_msg):\n",
    "    \"\"\"Log errors to a file.\"\"\"\n",
    "    with open(ERROR_LOG, 'a') as f:\n",
    "        f.write(f\"{datetime.now().isoformat()} - URL: {url} - Error: {error_msg}\\n\")\n",
    "\n",
    "def process_repos():\n",
    "    \"\"\"Process repositories from the CSV file and retrieve their stats.\"\"\"\n",
    "    df = pd.read_csv(INPUT_CSV)\n",
    "\n",
    "    # Load progress if it exists\n",
    "    if os.path.exists(PROGRESS_FILE):\n",
    "        with open(PROGRESS_FILE, 'r') as f:\n",
    "            progress = json.load(f)\n",
    "    else:\n",
    "        progress = {'processed': 0, 'stats': {}, 'valid_urls': 0, 'invalid_urls': 0, 'error_urls': 0}\n",
    "\n",
    "    # Create tqdm progress bar\n",
    "    pbar = tqdm(total=len(df), initial=progress['processed'], desc=\"Processing repositories\")\n",
    "\n",
    "    for index, row in df.iloc[progress['processed']:].iterrows():\n",
    "        url = row['url']\n",
    "        if not is_github_repo_url(url):\n",
    "            progress['invalid_urls'] += 1\n",
    "            pbar.update(1)\n",
    "            continue\n",
    "\n",
    "        progress['valid_urls'] += 1\n",
    "        owner, repo = url.split('/')[-2:]\n",
    "\n",
    "        for attempt in range(MAX_RETRIES):\n",
    "            try:\n",
    "                stats = get_repo_stats(owner, repo)\n",
    "                progress['stats'][url] = {\n",
    "                    'discussion_id': row['discussion_id'],\n",
    "                    'title': row['title'],\n",
    "                    'date': row['date'],\n",
    "                    'stars_history': stats['stars_history'],\n",
    "                    'forks_history': stats['forks_history']\n",
    "                }\n",
    "                break\n",
    "            except Exception as e:\n",
    "                error_msg = f\"{type(e).__name__}: {str(e)}\\n{traceback.format_exc()}\"\n",
    "                if attempt == MAX_RETRIES - 1:\n",
    "                    pbar.write(f\"Failed to process {url} after {MAX_RETRIES} attempts.\")\n",
    "                    pbar.write(f\"Error: {error_msg}\")\n",
    "                    log_error(url, error_msg)\n",
    "                    progress['error_urls'] += 1\n",
    "                else:\n",
    "                    pbar.write(f\"Attempt {attempt + 1} failed for {url}. Retrying...\")\n",
    "                    pbar.write(f\"Error: {error_msg}\")\n",
    "                    if \"Rate limit exceeded\" in str(e):\n",
    "                        sleep_time = int(str(e).split()[-2])\n",
    "                        pbar.write(f\"Rate limit exceeded. Sleeping for {sleep_time} seconds.\")\n",
    "                        time.sleep(sleep_time)\n",
    "                    else:\n",
    "                        time.sleep(5)\n",
    "\n",
    "        progress['processed'] = index + 1\n",
    "\n",
    "        # Save progress\n",
    "        with open(PROGRESS_FILE, 'w') as f:\n",
    "            json.dump(progress, f)\n",
    "\n",
    "        pbar.update(1)\n",
    "        pbar.set_postfix({\n",
    "            'Valid': progress['valid_urls'],\n",
    "            'Invalid': progress['invalid_urls'],\n",
    "            'Errors': progress['error_urls']\n",
    "        })\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    # Save final results\n",
    "    with open(OUTPUT_JSON, 'w') as f:\n",
    "        json.dump(progress, f)\n",
    "\n",
    "    print(f\"Processing complete. Valid URLs: {progress['valid_urls']}, Invalid URLs: {progress['invalid_urls']}, Error URLs: {progress['error_urls']}\")\n",
    "    print(f\"Detailed error log saved to {ERROR_LOG}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef76d382de443d4b92f44b72c59eb36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing repositories:   2%|2         | 8/354 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed for https://github.com/chidiwilliams/buzz. Retrying...\n",
      "Error: KeyError: 'created_at'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\prach\\AppData\\Local\\Temp\\ipykernel_14716\\4281034150.py\", line 69, in process_repos\n",
      "    stats = get_repo_stats(owner, repo)\n",
      "  File \"C:\\Users\\prach\\AppData\\Local\\Temp\\ipykernel_14716\\4281034150.py\", line 23, in get_repo_stats\n",
      "    timestamp = datetime.strptime(item['starred_at'] if 'starred_at' in item else item['created_at'], '%Y-%m-%dT%H:%M:%SZ').timestamp()\n",
      "KeyError: 'created_at'\n",
      "\n",
      "Attempt 2 failed for https://github.com/chidiwilliams/buzz. Retrying...\n",
      "Error: KeyError: 'created_at'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\prach\\AppData\\Local\\Temp\\ipykernel_14716\\4281034150.py\", line 69, in process_repos\n",
      "    stats = get_repo_stats(owner, repo)\n",
      "  File \"C:\\Users\\prach\\AppData\\Local\\Temp\\ipykernel_14716\\4281034150.py\", line 23, in get_repo_stats\n",
      "    timestamp = datetime.strptime(item['starred_at'] if 'starred_at' in item else item['created_at'], '%Y-%m-%dT%H:%M:%SZ').timestamp()\n",
      "KeyError: 'created_at'\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 69\u001b[0m, in \u001b[0;36mprocess_repos\u001b[1;34m()\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 69\u001b[0m     stats \u001b[38;5;241m=\u001b[39m \u001b[43mget_repo_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mowner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m     progress[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstats\u001b[39m\u001b[38;5;124m'\u001b[39m][url] \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     71\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiscussion_id\u001b[39m\u001b[38;5;124m'\u001b[39m: row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiscussion_id\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     72\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m: row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforks_history\u001b[39m\u001b[38;5;124m'\u001b[39m: stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforks_history\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     76\u001b[0m     }\n",
      "Cell \u001b[1;32mIn[13], line 23\u001b[0m, in \u001b[0;36mget_repo_stats\u001b[1;34m(owner, repo)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[1;32m---> 23\u001b[0m     timestamp \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mstrptime(item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstarred_at\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstarred_at\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m item \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcreated_at\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mSZ\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtimestamp()\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstarred_at\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m item:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'created_at'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run the processing\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mprocess_repos\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 93\u001b[0m, in \u001b[0;36mprocess_repos\u001b[1;34m()\u001b[0m\n\u001b[0;32m     91\u001b[0m                 time\u001b[38;5;241m.\u001b[39msleep(sleep_time)\n\u001b[0;32m     92\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 93\u001b[0m                 \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m progress[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# Save progress\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run the processing\n",
    "process_repos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
