{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import base64\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import pandas as pd\n",
    "import pytz\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "# Load access token\n",
    "load_dotenv()\n",
    "gh_token = os.getenv('ACCESS_TOKEN')\n",
    "print(gh_token)\n",
    "\n",
    "# GitHub API setup\n",
    "headers = {'Authorization': f'token {gh_token}'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the date to a datetime object\n",
    "cutoff_date = datetime(2022, 11, 30, tzinfo=pytz.utc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to filter commits by date, and check for .md file changes\n",
    "# Also counts the number of commits per snapshot\n",
    "snapshot_counts = {}\n",
    "\n",
    "def filter_commits(data):\n",
    "    filtered_commits = []\n",
    "    for commit in data:\n",
    "        if is_commit_after_cutoff_date(commit['CommitAt'], cutoff_date) and \\\n",
    "           is_commit_modifying_md_files(commit['Message']):\n",
    "            filtered_commits.append(commit)\n",
    "            snapshot_counts[commit['Snapshot']]['filtered'] += 1\n",
    "    return filtered_commits\n",
    "\n",
    "# Function to check if a commit is after the cutoff date\n",
    "def is_commit_after_cutoff_date(commit_datetime_str, cutoff_date):\n",
    "    commit_datetime = parse_commit_datetime(commit_datetime_str)\n",
    "    return commit_datetime and commit_datetime > cutoff_date\n",
    "\n",
    "# Function to check if a commit message indicates modification of .md files\n",
    "def is_commit_modifying_md_files(commit_message):\n",
    "    md_file_pattern = re.compile(r'\\b(\\S+\\.md)\\b', re.IGNORECASE)\n",
    "    return md_file_pattern.search(commit_message)\n",
    "\n",
    "# Function to parse the commit datetime string\n",
    "def parse_commit_datetime(datetime_str):\n",
    "    try:\n",
    "        # e.g. \"CommitAt\": \"2023-07-06T11:20:49.000-05:00\",\n",
    "        dt = datetime.strptime(datetime_str, '%Y-%m-%dT%H:%M:%S.%f%z')\n",
    "        return dt.astimezone(pytz.utc)\n",
    "    except ValueError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening snapshot files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total original size:  3245\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Paths to the JSON files\n",
    "paths = [\n",
    "    './snapshot_20230727/20230727_200003_commit_sharings.json',\n",
    "    './snapshot_20230803/20230803_095317_commit_sharings.json',\n",
    "    './snapshot_20230810/20230810_124807_commit_sharings.json',\n",
    "    './snapshot_20230817/20230817_131244_commit_sharings.json',\n",
    "    './snapshot_20230824/20230824_102435_commit_sharings.json',\n",
    "    './snapshot_20230831/20230831_063412_commit_sharings.json',\n",
    "    './snapshot_20230907/20230907_110036_commit_sharings.json',\n",
    "    './snapshot_20230914/20230914_083202_commit_sharings.json',\n",
    "    './snapshot_20231012/20231012_230826_commit_sharings.json',\n",
    "]\n",
    "\n",
    "data = []\n",
    "\n",
    "# Load the JSON data from each path and add the snapshot name to each commit\n",
    "for path in paths:\n",
    "    with open(path) as f:\n",
    "        d = json.load(f)\n",
    "        snapshot_name = path.split('/')[-1]  # Extract snapshot name from path\n",
    "        commits = d['Sources']\n",
    "        snapshot_counts[snapshot_name] = {'original': len(commits), 'filtered': 0}\n",
    "        for commit in commits:\n",
    "            commit['Snapshot'] = snapshot_name\n",
    "            data.append(commit)\n",
    "\n",
    "print('Total original size: ', len(data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filter and create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Filter the commits based on the cutoff date and .md file modifications\n",
    "filtered_commits = filter_commits(data)\n",
    "\n",
    "df = pd.DataFrame(filtered_commits, columns=['Snapshot', 'RepoName', 'Message', 'CommitAt', 'URL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove duplicated commits from different snapshots (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by snapshot date in descending order to prefer the latest snapshot\n",
    "df['Snapshot'] = pd.to_datetime(df['Snapshot'].str.extract(r'(\\d{8})')[0], format='%Y%m%d')\n",
    "df = df.sort_values(by='Snapshot', ascending=False)\n",
    "\n",
    "# Remove duplicate commits based on the 'URL' column, keeping the latest snapshot\n",
    "df = df.drop_duplicates(subset='URL', keep='first')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print the number of filtered commits from each snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original and filtered commit counts per snapshot:\n",
      "20230727_200003_commit_sharings.json: Original=179, Filtered=2\n",
      "20230803_095317_commit_sharings.json: Original=215, Filtered=4\n",
      "20230810_124807_commit_sharings.json: Original=305, Filtered=5\n",
      "20230817_131244_commit_sharings.json: Original=200, Filtered=7\n",
      "20230824_102435_commit_sharings.json: Original=200, Filtered=9\n",
      "20230831_063412_commit_sharings.json: Original=481, Filtered=11\n",
      "20230907_110036_commit_sharings.json: Original=400, Filtered=14\n",
      "20230914_083202_commit_sharings.json: Original=571, Filtered=11\n",
      "20231012_230826_commit_sharings.json: Original=694, Filtered=16\n"
     ]
    }
   ],
   "source": [
    "# Print the original and filtered commit counts for each snapshot\n",
    "print(\"\\nOriginal and filtered commit counts per snapshot:\")\n",
    "for snapshot, counts in snapshot_counts.items():\n",
    "    print(f\"{snapshot}: Original={counts['original']}, Filtered={counts['filtered']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print and export to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------+---------------------------------------+---------------------------------------------------------------------------------------------------------------------------------+-------------------------------+----------------------------------------------------------------------------------------------------------+\n",
      "|    | Snapshot            | RepoName                              | Message                                                                                                                         | CommitAt                      | URL                                                                                                      |\n",
      "|----+---------------------+---------------------------------------+---------------------------------------------------------------------------------------------------------------------------------+-------------------------------+----------------------------------------------------------------------------------------------------------|\n",
      "| 78 | 2023-10-12 00:00:00 | tisztamo/Junior                       | Refactor prompt.yaml creation and create projectSpecifics.md https://chat.openai.com/share/68fe4770-ee0e-4245-ab72-4fe09b45f4e9 | 2023-07-27T13:22:02.000+02:00 | https://github.com/tisztamo/Junior/commit/6f411731d6d2445f7c91bd2cedd481e67f5ce135                       |\n",
      "| 70 | 2023-10-12 00:00:00 | tisztamo/Junior                       | Update roadmap.md with completed task https://chat.openai.com/share/0bc5c1d5-f736-444a-a1c6-c8560afff010                        | 2023-08-07T15:56:34.000+02:00 | https://github.com/tisztamo/Junior/commit/8ba2f3d4ee07003a2c2a9b4096c09fbeef8fd389                       |\n",
      "| 63 | 2023-10-12 00:00:00 | Hajaradnan/Hajaradnan                 | Create README.md                                                                                                                | 2023-09-24T14:13:30.000+01:00 | https://github.com/Hajaradnan/Hajaradnan/commit/ec6241ca4370129bce7a021a4f80dff123cde103                 |\n",
      "|    |                     |                                       |                                                                                                                                 |                               |                                                                                                          |\n",
      "|    |                     |                                       | https://chat.openai.com/share/49eb1aff-ce9a-4373-ad28-348c2b5addcd                                                              |                               |                                                                                                          |\n",
      "| 64 | 2023-10-12 00:00:00 | eshreyareddy/prompting-zomato-reviews | Update README.md                                                                                                                | 2023-09-04T10:49:30.000+05:30 | https://github.com/eshreyareddy/prompting-zomato-reviews/commit/075750d66c6392147b7cccca28f7c225d9fa6545 |\n",
      "|    |                     |                                       |                                                                                                                                 |                               |                                                                                                          |\n",
      "|    |                     |                                       | https://chat.openai.com/share/52d67aed-45fa-451d-bb95-46d8ba642fa8                                                              |                               |                                                                                                          |\n",
      "| 65 | 2023-10-12 00:00:00 | tisztamo/vueyourcv                    | Update README.md                                                                                                                | 2023-06-26T13:49:10.000+02:00 | https://github.com/tisztamo/vueyourcv/commit/6d454ee9b01535bb252bcbdf2e0abf13b6bcda59                    |\n",
      "|    |                     |                                       |                                                                                                                                 |                               |                                                                                                          |\n",
      "|    |                     |                                       | https://chat.openai.com/share/be79a950-1231-4e55-aae0-2a90d8962d1d                                                              |                               |                                                                                                          |\n",
      "| 66 | 2023-10-12 00:00:00 | Hack23/cia                            | Update dashboard.md                                                                                                             | 2023-07-09T11:33:06.000+02:00 | https://github.com/Hack23/cia/commit/7b8639cb17b0da8317152148c1376851cf0832ee                            |\n",
      "|    |                     |                                       |                                                                                                                                 |                               |                                                                                                          |\n",
      "|    |                     |                                       | chatlog https://chat.openai.com/share/67ff0200-dad4-48f2-884e-ccada57974f6                                                      |                               |                                                                                                          |\n",
      "| 67 | 2023-10-12 00:00:00 | tisztamo/Junior                       | Update docs/descriptor.md https://chat.openai.com/share/f9d1c692-9808-49bf-8c4f-20e8acdef237                                    | 2023-08-22T16:13:49.000+02:00 | https://github.com/tisztamo/Junior/commit/9dac0b6b6797fb6d62cf41369227d0138f4397a5                       |\n",
      "| 69 | 2023-10-12 00:00:00 | tisztamo/Junior                       | Update README.md as per requirements https://chat.openai.com/share/c8be7d22-e7e6-48c3-83e4-b4b75e0db58f                         | 2023-08-08T12:11:35.000+02:00 | https://github.com/tisztamo/Junior/commit/37541a0776f2c369d5ec3c888c39beef1256e0b5                       |\n",
      "| 68 | 2023-10-12 00:00:00 | tisztamo/Junior                       | Improve documentation in docs/README.md https://chat.openai.com/share/1078eeab-70a4-45cb-a575-a0d8e2fb5313                      | 2023-08-18T22:52:16.000+02:00 | https://github.com/tisztamo/Junior/commit/fd0b5d400c7c86436abe3a2207ce61b9f9cf9c04                       |\n",
      "| 71 | 2023-10-12 00:00:00 | tisztamo/Junior                       | Improve documentation in usage.md https://chat.openai.com/share/a784f3e5-1e66-4249-a5e7-96ccf499d045                            | 2023-08-07T13:35:53.000+02:00 | https://github.com/tisztamo/Junior/commit/16f2f68315fd9a6a9a418a435196df592301509a                       |\n",
      "| 72 | 2023-10-12 00:00:00 | tisztamo/Junior                       | Improve Junior project's README.md https://chat.openai.com/share/524146cc-2dee-4a6b-91d9-a66597c45c1a                           | 2023-08-03T10:21:15.000+02:00 | https://github.com/tisztamo/Junior/commit/ed97ada1122ea1dee13ad3469b24c4cafb851f6c                       |\n",
      "| 73 | 2023-10-12 00:00:00 | tisztamo/Junior                       | Generate docs/config/env_or_cli.md for Junior configurations https://chat.openai.com/share/d7e0f6ad-02e2-4ffd-a670-91c0379d0e74 | 2023-09-29T16:26:34.000+02:00 | https://github.com/tisztamo/Junior/commit/d6f0d7ef512a35c1d348fbc419c212eb3688a217                       |\n",
      "| 74 | 2023-10-12 00:00:00 | tisztamo/Junior                       | Improve documentation in README.md https://chat.openai.com/share/e2b8c622-6a3f-417d-9142-fbf60643a965                           | 2023-07-31T11:29:54.000+02:00 | https://github.com/tisztamo/Junior/commit/c4c1c589da9229f9946dfb52d7f732d454ffe7ca                       |\n",
      "| 75 | 2023-10-12 00:00:00 | tisztamo/Junior                       | Update docs/open_jobs.md with project details https://chat.openai.com/share/8fc1705b-89fe-4582-8576-2d6b9c831b3f                | 2023-08-29T15:01:23.000+02:00 | https://github.com/tisztamo/Junior/commit/f844aad4f267f749cf65afb618f188a4263d575e                       |\n",
      "| 76 | 2023-10-12 00:00:00 | tisztamo/Junior                       | Rewrite system prompt in system.md to be concise https://chat.openai.com/share/e2cdc97c-ec36-452e-a6e1-646087e223f2             | 2023-08-09T14:07:28.000+02:00 | https://github.com/tisztamo/Junior/commit/2addc5f9963ce394cf10dbd25ac27fad50cd1732                       |\n",
      "| 77 | 2023-10-12 00:00:00 | tisztamo/Junior                       | Fix description of installedTools in docs/descriptor.md https://chat.openai.com/share/0df1cc4c-8454-457a-9cb2-d12298848036      | 2023-08-07T15:30:45.000+02:00 | https://github.com/tisztamo/Junior/commit/e2ea4fd627f1ccba0f50694dc0d9e94254657183                       |\n",
      "+----+---------------------+---------------------------------------+---------------------------------------------------------------------------------------------------------------------------------+-------------------------------+----------------------------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "# Print the filtered commits as a nicely formatted table\n",
    "print(tabulate(df, headers='keys', tablefmt='psql'))\n",
    "\n",
    "# Export the filtered commits to a CSV file\n",
    "df.to_csv('filtered_commits.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adding a list of modified files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading github api access token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "csv_path = './filtered_commits.csv'\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch modified files from a commit\n",
    "def get_modified_files(repo_name, commit_sha):\n",
    "    url = f'https://api.github.com/repos/{repo_name}/commits/{commit_sha}'\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        commit_data = response.json()\n",
    "\n",
    "        # Only retrieve modified files with .md\n",
    "        modified_files = [file['filename'] for file in commit_data['files'] if '.md' in file['filename']]\n",
    "        return modified_files\n",
    "    else:\n",
    "        print(f\"Failed to fetch commit {commit_sha} from repo {repo_name}: {response.status_code}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:10,  1.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# Process each commit\n",
    "modified_files_list = []\n",
    "for _, row in tqdm(df.iterrows()):\n",
    "    repo_name = row['RepoName']\n",
    "    commit_url = row['URL']\n",
    "    commit_sha = commit_url.split('/')[-1]\n",
    "\n",
    "    modified_files = get_modified_files(repo_name, commit_sha)\n",
    "    modified_files_list.append(modified_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the modified files to the DataFrame\n",
    "df['ModifiedFiles'] = modified_files_list\n",
    "\n",
    "# Save the updated DataFrame to a new CSV\n",
    "df.to_csv('updated_commits_with_modified_files2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# retrieving the modified files and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "csv_path = 'updated_commits_with_modified_files2.csv'\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the 'ModifiedFiles' column is read as a list of strings\n",
    "df['ModifiedFiles'] = df['ModifiedFiles'].apply(eval)\n",
    "\n",
    "# Define the base directory where the files will be saved\n",
    "base_dir = 'project_files4'\n",
    "\n",
    "# Create the base directory if it doesn't exist\n",
    "if not os.path.exists(base_dir):\n",
    "    os.makedirs(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to sanitize file paths for Windows\n",
    "def sanitize_path(path):\n",
    "    return re.sub(r'[<>:\"/\\\\|?*]', '_', path)\n",
    "\n",
    "# Function to fetch and save the content of a modified file from a commit\n",
    "def fetch_and_save_file_content(repo_name, commit_sha, filename):\n",
    "    file_url = f'https://raw.githubusercontent.com/{repo_name}/{commit_sha}/{filename}'\n",
    "    response = requests.get(file_url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # Sanitize the directory and file paths\n",
    "        sanitized_repo_name = sanitize_path(repo_name)\n",
    "        sanitized_commit_sha = sanitize_path(commit_sha)\n",
    "        sanitized_filename = sanitize_path(filename)\n",
    "\n",
    "        # Create directories for the file path if they don't exist\n",
    "        file_path = os.path.join(base_dir, sanitized_repo_name, sanitized_commit_sha, sanitized_filename)\n",
    "        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "\n",
    "        # Save the content to the file\n",
    "        with open(file_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(response.text)\n",
    "        print(f\"Saved: {file_path}\")\n",
    "    else:\n",
    "        print(f\"Failed to fetch {filename} from commit {commit_sha} in repo {repo_name}: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: project_files4\\tisztamo_Junior\\6f411731d6d2445f7c91bd2cedd481e67f5ce135\\prompt.md\n",
      "Saved: project_files4\\tisztamo_Junior\\8ba2f3d4ee07003a2c2a9b4096c09fbeef8fd389\\docs_roadmap.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:01,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: project_files4\\tisztamo_Junior\\8ba2f3d4ee07003a2c2a9b4096c09fbeef8fd389\\prompt.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:02,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: project_files4\\Hajaradnan_Hajaradnan\\ec6241ca4370129bce7a021a4f80dff123cde103\\README.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:03,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: project_files4\\eshreyareddy_prompting-zomato-reviews\\075750d66c6392147b7cccca28f7c225d9fa6545\\README.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:03,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: project_files4\\tisztamo_vueyourcv\\6d454ee9b01535bb252bcbdf2e0abf13b6bcda59\\README.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:04,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: project_files4\\Hack23_cia\\7b8639cb17b0da8317152148c1376851cf0832ee\\dashboard.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:04,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: project_files4\\tisztamo_Junior\\9dac0b6b6797fb6d62cf41369227d0138f4397a5\\docs_descriptor.md\n",
      "Saved: project_files4\\tisztamo_Junior\\37541a0776f2c369d5ec3c888c39beef1256e0b5\\docs_README.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:06,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: project_files4\\tisztamo_Junior\\37541a0776f2c369d5ec3c888c39beef1256e0b5\\prompt.md\n",
      "Saved: project_files4\\tisztamo_Junior\\fd0b5d400c7c86436abe3a2207ce61b9f9cf9c04\\docs_README.md\n",
      "Saved: project_files4\\tisztamo_Junior\\fd0b5d400c7c86436abe3a2207ce61b9f9cf9c04\\docs_README.md.backup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:07,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: project_files4\\tisztamo_Junior\\fd0b5d400c7c86436abe3a2207ce61b9f9cf9c04\\prompt.md\n",
      "Saved: project_files4\\tisztamo_Junior\\16f2f68315fd9a6a9a418a435196df592301509a\\docs_usage.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:09,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: project_files4\\tisztamo_Junior\\16f2f68315fd9a6a9a418a435196df592301509a\\prompt.md\n",
      "Saved: project_files4\\tisztamo_Junior\\ed97ada1122ea1dee13ad3469b24c4cafb851f6c\\README.md\n",
      "Saved: project_files4\\tisztamo_Junior\\ed97ada1122ea1dee13ad3469b24c4cafb851f6c\\prompt.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:10,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: project_files4\\tisztamo_Junior\\ed97ada1122ea1dee13ad3469b24c4cafb851f6c\\prompt_format_shell.md\n",
      "Saved: project_files4\\tisztamo_Junior\\d6f0d7ef512a35c1d348fbc419c212eb3688a217\\docs_config_env_or_cli.md\n",
      "Saved: project_files4\\tisztamo_Junior\\d6f0d7ef512a35c1d348fbc419c212eb3688a217\\prompt_history_2023_09_29_16_26_Generate docs_config_env_or_cli.md for Junior configurations_change.sh\n",
      "Saved: project_files4\\tisztamo_Junior\\d6f0d7ef512a35c1d348fbc419c212eb3688a217\\prompt_history_2023_09_29_16_26_Generate docs_config_env_or_cli.md for Junior configurations_prompt.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:13,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: project_files4\\tisztamo_Junior\\d6f0d7ef512a35c1d348fbc419c212eb3688a217\\prompt_history_2023_09_29_16_26_Generate docs_config_env_or_cli.md for Junior configurations_prompt.yaml\n",
      "Saved: project_files4\\tisztamo_Junior\\c4c1c589da9229f9946dfb52d7f732d454ffe7ca\\README.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:14,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: project_files4\\tisztamo_Junior\\c4c1c589da9229f9946dfb52d7f732d454ffe7ca\\prompt.md\n",
      "Saved: project_files4\\tisztamo_Junior\\f844aad4f267f749cf65afb618f188a4263d575e\\docs_open_jobs.md\n",
      "Saved: project_files4\\tisztamo_Junior\\f844aad4f267f749cf65afb618f188a4263d575e\\prompt_history_2023_08_29_14_57_Update docs_open_jobs.md with project details_change.sh\n",
      "Saved: project_files4\\tisztamo_Junior\\f844aad4f267f749cf65afb618f188a4263d575e\\prompt_history_2023_08_29_14_57_Update docs_open_jobs.md with project details_prompt.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:16,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: project_files4\\tisztamo_Junior\\f844aad4f267f749cf65afb618f188a4263d575e\\prompt_history_2023_08_29_14_57_Update docs_open_jobs.md with project details_prompt.yaml\n",
      "Saved: project_files4\\tisztamo_Junior\\2addc5f9963ce394cf10dbd25ac27fad50cd1732\\prompt.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:17,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: project_files4\\tisztamo_Junior\\2addc5f9963ce394cf10dbd25ac27fad50cd1732\\prompt_system.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:18,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: project_files4\\tisztamo_Junior\\e2ea4fd627f1ccba0f50694dc0d9e94254657183\\docs_descriptor.md\n",
      "All files have been fetched and saved to the local project folder.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each row in the DataFrame\n",
    "for _, row in tqdm(df.iterrows()):\n",
    "    repo_name = row['RepoName']\n",
    "    commit_url = row['URL']\n",
    "    commit_sha = commit_url.split('/')[-1]\n",
    "    modified_files = row['ModifiedFiles']\n",
    "\n",
    "    for filename in modified_files:\n",
    "        # Ugly solution to skip non-markdown files\n",
    "        if '.md' not in filename:\n",
    "            continue\n",
    "\n",
    "        fetch_and_save_file_content(repo_name, commit_sha, filename)\n",
    "\n",
    "print(\"All files have been fetched and saved to the local project folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# retrieving commits containing the modified files before chatgpt releases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Load the data\n",
    "csv_path = 'updated_commits_with_modified_files2.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Ensure the 'ModifiedFiles' column is read as a list of strings\n",
    "df['ModifiedFiles'] = df['ModifiedFiles'].apply(eval)\n",
    "\n",
    "# Define the date threshold\n",
    "date_threshold = datetime(2022, 10, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch commit history of a specific file up to a specific date\n",
    "def fetch_commit_history_for_file(repo_name, file_path, date_threshold):\n",
    "    commits = []\n",
    "    page = 1\n",
    "    while True:\n",
    "        # url = f'https://api.github.com/repos/{repo_name}/commits?path={file_path}&until={date_threshold.isoformat()}'\n",
    "        url = f'https://api.github.com/repos/{repo_name}/commits?path={file_path}'\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code != 200:\n",
    "            break\n",
    "        page_commits = response.json()\n",
    "        if not page_commits:\n",
    "            break\n",
    "        commits.extend(page_commits)\n",
    "        page += 1\n",
    "    print(commits)\n",
    "    return commits\n",
    "\n",
    "# Function to find the commit with matching modified files\n",
    "def find_matching_commit(repo_name, target_files, date_threshold):\n",
    "    file_commits = {}\n",
    "    for file in target_files:\n",
    "        print(f\"Fetching commit history for file: {file}\")\n",
    "        file_commits[file] = fetch_commit_history_for_file(repo_name, file, date_threshold)\n",
    "\n",
    "    # Find the latest commit that modifies all target files\n",
    "    common_commits = set(file_commits[target_files[0]])\n",
    "    for file in target_files[1:]:\n",
    "        common_commits.intersection_update(file_commits[file])\n",
    "\n",
    "    for commit in sorted(common_commits, key=lambda x: x['commit']['author']['date'], reverse=True):\n",
    "        sha = commit['sha']\n",
    "        commit_url = commit['html_url']\n",
    "        commit_date = commit['commit']['author']['date']\n",
    "        commit_message = commit['commit']['message']\n",
    "        return {\n",
    "            'RepoName': repo_name,\n",
    "            'Message': commit_message,\n",
    "            'CommitAt': commit_date,\n",
    "            'URL': commit_url,\n",
    "            'ModifiedFiles': target_files\n",
    "        }\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1/16: tisztamo/Junior\n",
      "Fetching commit history for file: prompt.md\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='api.github.com', port=443): Max retries exceeded with url: /repos/tisztamo/Junior/commits?path=prompt.md (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001E2B42D3DF0>: Failed to establish a new connection: [WinError 10051] A socket operation was attempted to an unreachable network'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 174\u001b[0m     conn \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mcreate_connection(\n\u001b[0;32m    175\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dns_host, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_kw\n\u001b[0;32m    176\u001b[0m     )\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\util\\connection.py:95\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m socket\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgetaddrinfo returns an empty list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\util\\connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     84\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 85\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sock\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 10051] A socket operation was attempted to an unreachable network",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:386\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 386\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;66;03m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1042\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msock\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[1;32m-> 1042\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connection.py:363\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;66;03m# Add certificate verification\u001b[39;00m\n\u001b[1;32m--> 363\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    364\u001b[0m     hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connection.py:186\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m e\n\u001b[0;32m    188\u001b[0m     )\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conn\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x000001E2B42D3DF0>: Failed to establish a new connection: [WinError 10051] A socket operation was attempted to an unreachable network",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    785\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[1;32m--> 787\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    790\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\urllib3\\util\\retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_retry\u001b[38;5;241m.\u001b[39mis_exhausted():\n\u001b[1;32m--> 592\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause))\n\u001b[0;32m    594\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='api.github.com', port=443): Max retries exceeded with url: /repos/tisztamo/Junior/commits?path=prompt.md (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001E2B42D3DF0>: Failed to establish a new connection: [WinError 10051] A socket operation was attempted to an unreachable network'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_rows\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Find the commit with matching modified files\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m matching_commit \u001b[38;5;241m=\u001b[39m \u001b[43mfind_matching_commit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate_threshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m matching_commit:\n\u001b[0;32m     22\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(matching_commit)\n",
      "Cell \u001b[1;32mIn[22], line 24\u001b[0m, in \u001b[0;36mfind_matching_commit\u001b[1;34m(repo_name, target_files, date_threshold)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m target_files:\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetching commit history for file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m     file_commits[file] \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_commit_history_for_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate_threshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Find the latest commit that modifies all target files\u001b[39;00m\n\u001b[0;32m     27\u001b[0m common_commits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(file_commits[target_files[\u001b[38;5;241m0\u001b[39m]])\n",
      "Cell \u001b[1;32mIn[22], line 8\u001b[0m, in \u001b[0;36mfetch_commit_history_for_file\u001b[1;34m(repo_name, file_path, date_threshold)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# url = f'https://api.github.com/repos/{repo_name}/commits?path={file_path}&until={date_threshold.isoformat()}'\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://api.github.com/repos/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/commits?path=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 8\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\adapters.py:519\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    515\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[0;32m    516\u001b[0m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[0;32m    517\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    522\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='api.github.com', port=443): Max retries exceeded with url: /repos/tisztamo/Junior/commits?path=prompt.md (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000001E2B42D3DF0>: Failed to establish a new connection: [WinError 10051] A socket operation was attempted to an unreachable network'))"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "# Initialize a list to store the results\n",
    "results = []\n",
    "\n",
    "# Total number of rows for progress tracking\n",
    "total_rows = len(df)\n",
    "start_time = time.time()\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for idx, row in df.iterrows():\n",
    "    repo_name = row['RepoName']\n",
    "    target_files = row['ModifiedFiles']\n",
    "\n",
    "    print(f\"Processing {idx + 1}/{total_rows}: {repo_name}\")\n",
    "\n",
    "    # Find the commit with matching modified files\n",
    "    matching_commit = find_matching_commit(repo_name, target_files, date_threshold)\n",
    "\n",
    "    if matching_commit:\n",
    "        results.append(matching_commit)\n",
    "\n",
    "    # Print progress\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Processed {idx + 1}/{total_rows} in {elapsed_time:.2f} seconds\")\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Save the results to a new CSV file\n",
    "results_csv_path = './matching_commits_before_chatgpt.csv'\n",
    "results_df.to_csv(results_csv_path, index=False)\n",
    "\n",
    "print(f\"Matching commits have been saved to {results_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
